{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "adversarial_attack.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KD1nuZz8w2cA"
      },
      "source": [
        "# Global Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGWYp1d4tCw-"
      },
      "source": [
        "from __future__ import print_function, absolute_import\n",
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "from PIL import Image\n",
        "import shutil\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__SGGPt-wXDs"
      },
      "source": [
        "# Global Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtOulzw8v2so"
      },
      "source": [
        "# Gloablly defined variables\n",
        "arch_names = ['resnet','wrn']  # The names of the model architectures\n",
        "attack_names = ['PGD','FAB','FGSM','FIFGSM']  # The names of the attack architectures\n",
        "dataset_names = ['fashionmnist', 'emnist']  # The names of the dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clNvMId_4LQf"
      },
      "source": [
        "# Load Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54s4aOPoIQmP"
      },
      "source": [
        "## Simple CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdoJFH2WISOr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6q82uj-tedM"
      },
      "source": [
        "## Resnet\n",
        "Resnet for cifar dataset. \n",
        "\n",
        "Ported form \n",
        "https://github.com/facebook/fb.resnet.torch\n",
        "\n",
        "\n",
        "https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py\n",
        "\n",
        "(c) YANG, Wei \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISEJF41Jtca4"
      },
      "source": [
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"3x3 convolution with padding\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "class BasicBlockRes(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlockRes, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, depth, num_classes=1000):\n",
        "        super(ResNet, self).__init__()\n",
        "        # Model type specifies number of layers for CIFAR-10 model\n",
        "        assert (depth - 2) % 6 == 0, 'depth should be 6n+2'\n",
        "        n = (depth - 2) / 6\n",
        "\n",
        "        block = Bottleneck if depth >=44 else BasicBlockRes\n",
        "\n",
        "        self.inplanes = 16\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = self._make_layer(block, 16, n)\n",
        "        self.layer2 = self._make_layer(block, 32, n, stride=2)\n",
        "        self.layer3 = self._make_layer(block, 64, n, stride=2)\n",
        "        self.avgpool = nn.AvgPool2d(7)\n",
        "        self.fc = nn.Linear(64 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, int(blocks)):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)    # 32x32\n",
        "\n",
        "        x = self.layer1(x)  # 32x32\n",
        "        x = self.layer2(x)  # 16x16\n",
        "        x = self.layer3(x)  # 8x8\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "def resnet(**kwargs):\n",
        "    \"\"\"\n",
        "    Constructs a ResNet model.\n",
        "    \"\"\"\n",
        "    return ResNet(**kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6a3jCuTvmOo"
      },
      "source": [
        "# rs_model = resnet(depth = 14)\n",
        "# print(rs_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSFdhs6KyiVe"
      },
      "source": [
        "## WRN\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgz-aYeZygx5"
      },
      "source": [
        "class BasicBlockWRN(nn.Module):\n",
        "    def __init__(self, in_planes, out_planes, stride, dropRate=0.0):\n",
        "        super(BasicBlockWRN, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1,\n",
        "                               padding=1, bias=False)\n",
        "        self.droprate = dropRate\n",
        "        self.equalInOut = (in_planes == out_planes)\n",
        "        self.convShortcut = (not self.equalInOut) and nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride,\n",
        "                               padding=0, bias=False) or None\n",
        "    def forward(self, x):\n",
        "        if not self.equalInOut:\n",
        "            x = self.relu1(self.bn1(x))\n",
        "        else:\n",
        "            out = self.relu1(self.bn1(x))\n",
        "        out = self.relu2(self.bn2(self.conv1(out if self.equalInOut else x)))\n",
        "        if self.droprate > 0:\n",
        "            out = F.dropout(out, p=self.droprate, training=self.training)\n",
        "        out = self.conv2(out)\n",
        "        return torch.add(x if self.equalInOut else self.convShortcut(x), out)\n",
        "\n",
        "class NetworkBlock(nn.Module):\n",
        "    def __init__(self, nb_layers, in_planes, out_planes, block, stride, dropRate=0.0):\n",
        "        super(NetworkBlock, self).__init__()\n",
        "        self.layer = self._make_layer(block, in_planes, out_planes, nb_layers, stride, dropRate)\n",
        "    def _make_layer(self, block, in_planes, out_planes, nb_layers, stride, dropRate):\n",
        "        layers = []\n",
        "        for i in range(nb_layers):\n",
        "            layers.append(block(i == 0 and in_planes or out_planes, out_planes, i == 0 and stride or 1, dropRate))\n",
        "        return nn.Sequential(*layers)\n",
        "    def forward(self, x):\n",
        "        return self.layer(x)\n",
        "\n",
        "class WideResNet(nn.Module):\n",
        "    def __init__(self, depth, num_classes, widen_factor=1, dropRate=0.0):\n",
        "        super(WideResNet, self).__init__()\n",
        "        nChannels = [16, 16*widen_factor, 32*widen_factor, 64*widen_factor]\n",
        "        assert (depth - 4) % 6 == 0, 'depth should be 6n+4'\n",
        "        n = (depth - 4) // 6\n",
        "        block = BasicBlockWRN\n",
        "        # 1st conv before any network block\n",
        "        self.conv1 = nn.Conv2d(1, nChannels[0], kernel_size=3, stride=1,\n",
        "                               padding=1, bias=False)\n",
        "        # 1st block\n",
        "        self.block1 = NetworkBlock(n, nChannels[0], nChannels[1], block, 1, dropRate)\n",
        "        # 2nd block\n",
        "        self.block2 = NetworkBlock(n, nChannels[1], nChannels[2], block, 2, dropRate)\n",
        "        # 3rd block\n",
        "        self.block3 = NetworkBlock(n, nChannels[2], nChannels[3], block, 2, dropRate)\n",
        "        # global average pooling and classifier\n",
        "        self.bn1 = nn.BatchNorm2d(nChannels[3])\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.fc = nn.Linear(nChannels[3], num_classes)\n",
        "        self.nChannels = nChannels[3]\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                m.bias.data.zero_()\n",
        "                \n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.block1(out)\n",
        "        out = self.block2(out)\n",
        "        out = self.block3(out)\n",
        "        out = self.relu(self.bn1(out))\n",
        "        out = F.avg_pool2d(out, 7)\n",
        "        out = out.view(-1, self.nChannels)\n",
        "        return self.fc(out)\n",
        "\n",
        "def wrn(**kwargs):\n",
        "    \"\"\"\n",
        "    Constructs a Wide Residual Networks.\n",
        "    \"\"\"\n",
        "    model = WideResNet(**kwargs)\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SF4xXj8LzpmI"
      },
      "source": [
        "# wrn_model = wrn(depth = 16, num_classes=10)\n",
        "# print(wrn_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWfCMsG4IL9n"
      },
      "source": [
        "## Efficient Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdPBarPbIOt7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsJ92nBW2VQn"
      },
      "source": [
        "#Load Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNL4S6uZxHX_"
      },
      "source": [
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U24-SRgb2ATW"
      },
      "source": [
        "### Logger Utils\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "br4TIyfZ1nWK"
      },
      "source": [
        "# A simple torch style logger\n",
        "# (C) Wei YANG 2017\n",
        "def savefig(fname, dpi=None):\n",
        "    dpi = 150 if dpi == None else dpi\n",
        "    plt.savefig(fname, dpi=dpi)\n",
        "    \n",
        "def plot_overlap(logger, names=None):\n",
        "    names = logger.names if names == None else names\n",
        "    numbers = logger.numbers\n",
        "    for _, name in enumerate(names):\n",
        "        x = np.arange(len(numbers[name]))\n",
        "        if name in ['Train Acc.', 'Valid Acc.']:\n",
        "            plt.plot(x, 100-np.asarray(numbers[name], dtype='float'))\n",
        "        else:\n",
        "            plt.plot(x, np.asarray(numbers[name]))\n",
        "    return [logger.title + '(' + name + ')' for name in names]\n",
        "\n",
        "class Logger(object):\n",
        "    '''Save training process to log file with simple plot function.'''\n",
        "    def __init__(self, fpath, title=None, resume=False): \n",
        "        self.file = None\n",
        "        self.resume = resume\n",
        "        self.title = '' if title == None else title\n",
        "        if fpath is not None:\n",
        "            if resume: \n",
        "                self.file = open(fpath, 'r') \n",
        "                name = self.file.readline()\n",
        "                self.names = name.rstrip().split('\\t')\n",
        "                self.numbers = {}\n",
        "                for _, name in enumerate(self.names):\n",
        "                    self.numbers[name] = []\n",
        "\n",
        "                for numbers in self.file:\n",
        "                    numbers = numbers.rstrip().split('\\t')\n",
        "                    for i in range(0, len(numbers)):\n",
        "                        self.numbers[self.names[i]].append(numbers[i])\n",
        "                self.file.close()\n",
        "                self.file = open(fpath, 'a')  \n",
        "            else:\n",
        "                self.file = open(fpath, 'w')\n",
        "\n",
        "    def set_names(self, names):\n",
        "        if self.resume: \n",
        "            pass\n",
        "        # initialize numbers as empty list\n",
        "        self.numbers = {}\n",
        "        self.names = names\n",
        "        for _, name in enumerate(self.names):\n",
        "            self.file.write(name)\n",
        "            self.file.write('\\t')\n",
        "            self.numbers[name] = []\n",
        "        self.file.write('\\n')\n",
        "        self.file.flush()\n",
        "\n",
        "\n",
        "    def append(self, numbers):\n",
        "        assert len(self.names) == len(numbers), 'Numbers do not match names'\n",
        "        for index, num in enumerate(numbers):\n",
        "            self.file.write(\"{0:.6f}\".format(num))\n",
        "            self.file.write('\\t')\n",
        "            self.numbers[self.names[index]].append(num)\n",
        "        self.file.write('\\n')\n",
        "        self.file.flush()\n",
        "\n",
        "    def plot(self, names=None):   \n",
        "        names = self.names if names == None else names\n",
        "        numbers = self.numbers\n",
        "        for _, name in enumerate(names):\n",
        "            x = np.arange(len(numbers[name]))\n",
        "            plt.plot(x, np.asarray(numbers[name]))\n",
        "        plt.legend([self.title + '(' + name + ')' for name in names])\n",
        "        plt.grid(True)\n",
        "\n",
        "    def close(self):\n",
        "        if self.file is not None:\n",
        "            self.file.close()\n",
        "\n",
        "class LoggerMonitor(object):\n",
        "    '''Load and visualize multiple logs.'''\n",
        "    def __init__ (self, paths):\n",
        "        '''paths is a distionary with {name:filepath} pair'''\n",
        "        self.loggers = []\n",
        "        for title, path in paths.items():\n",
        "            logger = Logger(path, title=title, resume=True)\n",
        "            self.loggers.append(logger)\n",
        "\n",
        "    def plot(self, names=None):\n",
        "        plt.figure()\n",
        "        plt.plot()\n",
        "        legend_text = []\n",
        "        for logger in self.loggers:\n",
        "            legend_text += plot_overlap(logger, names)\n",
        "        legend_text = ['WRN-28-10+Ours (error 17.65%)', 'WRN-28-10 (error 18.68%)']\n",
        "        plt.legend(legend_text, loc=0)\n",
        "        plt.ylabel('test error (%)')\n",
        "        plt.xlabel('epoch')\n",
        "        plt.grid(True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0m8YuDJW1z0-"
      },
      "source": [
        "### Eval Utils\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B52goabL2oUw"
      },
      "source": [
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
        "    maxk = max(topk)\n",
        "    batch_size = target.size(0)\n",
        "\n",
        "    _, pred = output.topk(maxk, 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "    res = []\n",
        "    for k in topk:\n",
        "        correct_k = sum(correct[:k].float().sum(0))\n",
        "        res.append(correct_k.mul_(100.0 / batch_size))\n",
        "    return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRzPXsxk1_N6"
      },
      "source": [
        "### Misc Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ly-G3az3xX_6"
      },
      "source": [
        "import errno\n",
        "import time\n",
        "import torch.nn.init as init\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onJAHW2d25xX"
      },
      "source": [
        "'''Some helper functions for PyTorch, including:\n",
        "    - get_mean_and_std: calculate the mean and std value of dataset.\n",
        "    - msr_init: net parameter initialization.\n",
        "    - progress_bar: progress bar mimic xlua.progress.\n",
        "'''\n",
        "\n",
        "__all__ = ['get_mean_and_std', 'init_params', 'mkdir_p', 'AverageMeter']\n",
        "\n",
        "\n",
        "def get_mean_and_std(dataset):\n",
        "    '''Compute the mean and std value of dataset.'''\n",
        "    dataloader = trainloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=2)\n",
        "\n",
        "    mean = torch.zeros(3)\n",
        "    std = torch.zeros(3)\n",
        "    print('==> Computing mean and std..')\n",
        "    for inputs, targets in dataloader:\n",
        "        for i in range(3):\n",
        "            mean[i] += inputs[:,i,:,:].mean()\n",
        "            std[i] += inputs[:,i,:,:].std()\n",
        "    mean.div_(len(dataset))\n",
        "    std.div_(len(dataset))\n",
        "    return mean, std\n",
        "\n",
        "def init_params(net):\n",
        "    '''Init layer parameters.'''\n",
        "    for m in net.modules():\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            init.kaiming_normal(m.weight, mode='fan_out')\n",
        "            if m.bias:\n",
        "                init.constant(m.bias, 0)\n",
        "        elif isinstance(m, nn.BatchNorm2d):\n",
        "            init.constant(m.weight, 1)\n",
        "            init.constant(m.bias, 0)\n",
        "        elif isinstance(m, nn.Linear):\n",
        "            init.normal(m.weight, std=1e-3)\n",
        "            if m.bias:\n",
        "                init.constant(m.bias, 0)\n",
        "\n",
        "def mkdir_p(path):\n",
        "    '''make dir if not exist'''\n",
        "    try:\n",
        "        os.makedirs(path)\n",
        "    except OSError as exc:  # Python >2.5\n",
        "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
        "            pass\n",
        "        else:\n",
        "            raise\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4X9BaWX83QlN"
      },
      "source": [
        "### Transform Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBGfDc1kxUWz"
      },
      "source": [
        "from torchvision.transforms import *\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8ANdQGK3Noz"
      },
      "source": [
        "class RandomErasing(object):\n",
        "    '''\n",
        "    Class that performs Random Erasing in Random Erasing Data Augmentation by Zhong et al. \n",
        "    -------------------------------------------------------------------------------------\n",
        "    probability: The probability that the operation will be performed.\n",
        "    sl: min erasing area\n",
        "    sh: max erasing area\n",
        "    r1: min aspect ratio\n",
        "    mean: erasing value\n",
        "    -------------------------------------------------------------------------------------\n",
        "    '''\n",
        "    def __init__(self, probability = 0.5, sl = 0.02, sh = 0.4, r1 = 0.3, mean=[0.4914, 0.4822, 0.4465]):\n",
        "        self.probability = probability\n",
        "        self.mean = mean\n",
        "        self.sl = sl\n",
        "        self.sh = sh\n",
        "        self.r1 = r1\n",
        "       \n",
        "    def __call__(self, img):\n",
        "\n",
        "        if random.uniform(0, 1) > self.probability:\n",
        "            return img\n",
        "\n",
        "        for attempt in range(100):\n",
        "            area = img.size()[1] * img.size()[2]\n",
        "       \n",
        "            target_area = random.uniform(self.sl, self.sh) * area\n",
        "            aspect_ratio = random.uniform(self.r1, 1/self.r1)\n",
        "\n",
        "            h = int(round(math.sqrt(target_area * aspect_ratio)))\n",
        "            w = int(round(math.sqrt(target_area / aspect_ratio)))\n",
        "\n",
        "            if w < img.size()[2] and h < img.size()[1]:\n",
        "                x1 = random.randint(0, img.size()[1] - h)\n",
        "                y1 = random.randint(0, img.size()[2] - w)\n",
        "                if img.size()[0] == 3:\n",
        "                    img[0, x1:x1+h, y1:y1+w] = self.mean[0]\n",
        "                    img[1, x1:x1+h, y1:y1+w] = self.mean[1]\n",
        "                    img[2, x1:x1+h, y1:y1+w] = self.mean[2]\n",
        "                else:\n",
        "                    img[0, x1:x1+h, y1:y1+w] = self.mean[0]\n",
        "                return img\n",
        "\n",
        "        return img\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3BNIbVx3bau"
      },
      "source": [
        "Visualize Utils\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AJ-Jmco3dvP"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "\n",
        "__all__ = ['make_image', 'show_batch', 'show_mask', 'show_mask_single']\n",
        "\n",
        "# functions to show an image\n",
        "def make_image(img, mean=(0,0,0), std=(1,1,1)):\n",
        "    for i in range(0, 3):\n",
        "        img[i] = img[i] * std[i] + mean[i]    # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    return np.transpose(npimg, (1, 2, 0))\n",
        "\n",
        "def gauss(x,a,b,c):\n",
        "    return torch.exp(-torch.pow(torch.add(x,-b),2).div(2*c*c)).mul(a)\n",
        "\n",
        "def colorize(x):\n",
        "    ''' Converts a one-channel grayscale image to a color heatmap image '''\n",
        "    if x.dim() == 2:\n",
        "        torch.unsqueeze(x, 0, out=x)\n",
        "    if x.dim() == 3:\n",
        "        cl = torch.zeros([3, x.size(1), x.size(2)])\n",
        "        cl[0] = gauss(x,.5,.6,.2) + gauss(x,1,.8,.3)\n",
        "        cl[1] = gauss(x,1,.5,.3)\n",
        "        cl[2] = gauss(x,1,.2,.3)\n",
        "        cl[cl.gt(1)] = 1\n",
        "    elif x.dim() == 4:\n",
        "        cl = torch.zeros([x.size(0), 3, x.size(2), x.size(3)])\n",
        "        cl[:,0,:,:] = gauss(x,.5,.6,.2) + gauss(x,1,.8,.3)\n",
        "        cl[:,1,:,:] = gauss(x,1,.5,.3)\n",
        "        cl[:,2,:,:] = gauss(x,1,.2,.3)\n",
        "    return cl\n",
        "\n",
        "def show_batch(images, Mean=(2, 2, 2), Std=(0.5,0.5,0.5)):\n",
        "    images = make_image(torchvision.utils.make_grid(images), Mean, Std)\n",
        "    plt.imshow(images)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def show_mask_single(images, mask, Mean=(2, 2, 2), Std=(0.5,0.5,0.5)):\n",
        "    im_size = images.size(2)\n",
        "\n",
        "    # save for adding mask\n",
        "    im_data = images.clone()\n",
        "    for i in range(0, 3):\n",
        "        im_data[:,i,:,:] = im_data[:,i,:,:] * Std[i] + Mean[i]    # unnormalize\n",
        "\n",
        "    images = make_image(torchvision.utils.make_grid(images), Mean, Std)\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.imshow(images)\n",
        "    plt.axis('off')\n",
        "\n",
        "    # for b in range(mask.size(0)):\n",
        "    #     mask[b] = (mask[b] - mask[b].min())/(mask[b].max() - mask[b].min())\n",
        "    mask_size = mask.size(2)\n",
        "    # print('Max %f Min %f' % (mask.max(), mask.min()))\n",
        "    mask = (upsampling(mask, scale_factor=im_size/mask_size))\n",
        "    # mask = colorize(upsampling(mask, scale_factor=im_size/mask_size))\n",
        "    # for c in range(3):\n",
        "    #     mask[:,c,:,:] = (mask[:,c,:,:] - Mean[c])/Std[c]\n",
        "\n",
        "    # print(mask.size())\n",
        "    mask = make_image(torchvision.utils.make_grid(0.3*im_data+0.7*mask.expand_as(im_data)))\n",
        "    # mask = make_image(torchvision.utils.make_grid(0.3*im_data+0.7*mask), Mean, Std)\n",
        "    plt.subplot(2, 1, 2)\n",
        "    plt.imshow(mask)\n",
        "    plt.axis('off')\n",
        "\n",
        "def show_mask(images, masklist, Mean=(2, 2, 2), Std=(0.5,0.5,0.5)):\n",
        "    im_size = images.size(2)\n",
        "\n",
        "    # save for adding mask\n",
        "    im_data = images.clone()\n",
        "    for i in range(0, 3):\n",
        "        im_data[:,i,:,:] = im_data[:,i,:,:] * Std[i] + Mean[i]    # unnormalize\n",
        "\n",
        "    images = make_image(torchvision.utils.make_grid(images), Mean, Std)\n",
        "    plt.subplot(1+len(masklist), 1, 1)\n",
        "    plt.imshow(images)\n",
        "    plt.axis('off')\n",
        "\n",
        "    for i in range(len(masklist)):\n",
        "        mask = masklist[i].data.cpu()\n",
        "        # for b in range(mask.size(0)):\n",
        "        #     mask[b] = (mask[b] - mask[b].min())/(mask[b].max() - mask[b].min())\n",
        "        mask_size = mask.size(2)\n",
        "        # print('Max %f Min %f' % (mask.max(), mask.min()))\n",
        "        mask = (upsampling(mask, scale_factor=im_size/mask_size))\n",
        "        # mask = colorize(upsampling(mask, scale_factor=im_size/mask_size))\n",
        "        # for c in range(3):\n",
        "        #     mask[:,c,:,:] = (mask[:,c,:,:] - Mean[c])/Std[c]\n",
        "\n",
        "        # print(mask.size())\n",
        "        mask = make_image(torchvision.utils.make_grid(0.3*im_data+0.7*mask.expand_as(im_data)))\n",
        "        # mask = make_image(torchvision.utils.make_grid(0.3*im_data+0.7*mask), Mean, Std)\n",
        "        plt.subplot(1+len(masklist), 1, i+2)\n",
        "        plt.imshow(mask)\n",
        "        plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKXgm8Ij0K6L"
      },
      "source": [
        "#Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDmjFVEH1A7z",
        "outputId": "94b92ec6-bd53-4a68-f0bb-39d82acfbd08"
      },
      "source": [
        "!pip install emnist"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: emnist in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from emnist) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from emnist) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from emnist) (4.41.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->emnist) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->emnist) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->emnist) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->emnist) (2020.12.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9vHNQ7nxjRe"
      },
      "source": [
        "import torch.utils.data as data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7C346Pvt1McI"
      },
      "source": [
        "class CustomDataset(data.Dataset):\n",
        "\n",
        "    def __init__(self, X, y, transform=None):\n",
        "\n",
        "        self.features = X\n",
        "        self.label = y\n",
        "        self.transfrom = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        X = self.features[index]\n",
        "        X = Image.fromarray(X, 'L')\n",
        "        if self.transfrom:\n",
        "            X = self.transfrom(X)\n",
        "        y = self.label[index]\n",
        "        return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzaRrdJXqr5D"
      },
      "source": [
        "# Set Attack Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3vhBdMZqrCe"
      },
      "source": [
        "# TODO: Only set FAB and PGD as examples, will add more attack methods later\n",
        "class Attack(object):\n",
        "    r\"\"\"\n",
        "    Base class for all attacks.\n",
        "\n",
        "    .. note::\n",
        "        It automatically set device to the device where given model is.\n",
        "        It temporarily changes the model's training mode to `test`\n",
        "        by `.eval()` only during an attack process.\n",
        "    \"\"\"\n",
        "    def __init__(self, name, model):\n",
        "        r\"\"\"\n",
        "        Initializes internal attack state.\n",
        "\n",
        "        Arguments:\n",
        "            name (str): name of an attack.\n",
        "            model (torch.nn.Module): model to attack.\n",
        "        \"\"\"\n",
        "\n",
        "        self.attack = name\n",
        "        self.model = model\n",
        "        self.model_name = str(model).split(\"(\")[0]\n",
        "\n",
        "        self.training = model.training\n",
        "        self.device = next(model.parameters()).device\n",
        "        \n",
        "        self._transform_label = self._get_label\n",
        "        self._targeted = -1\n",
        "        self._attack_mode = 'default'\n",
        "        self._return_type = 'float'\n",
        "        self._kth_min = 1\n",
        "\n",
        "    def forward(self, *input):\n",
        "        r\"\"\"\n",
        "        It defines the computation performed at every call.\n",
        "        Should be overridden by all subclasses.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "            \n",
        "    def set_mode_default(self):\n",
        "        r\"\"\"\n",
        "        Set attack mode as default mode.\n",
        "\n",
        "        \"\"\"\n",
        "        if self._attack_mode == 'only_default':\n",
        "            self._attack_mode = \"only_default\"\n",
        "        else:\n",
        "            self._attack_mode = \"default\"\n",
        "            \n",
        "        self._targeted = -1\n",
        "        self._transform_label = self._get_label\n",
        "        \n",
        "    def set_mode_targeted(self, target_map_function=None):\n",
        "        r\"\"\"\n",
        "        Set attack mode as targeted mode.\n",
        "  \n",
        "        Arguments:\n",
        "            target_map_function (function): Label mapping function.\n",
        "                e.g. lambda images, labels:(labels+1)%10.\n",
        "                None for using input labels as targeted labels. (DEFAULT)\n",
        "\n",
        "        \"\"\"\n",
        "        if self._attack_mode == 'only_default':\n",
        "            raise ValueError(\"Changing attack mode is not supported in this attack method.\")\n",
        "            \n",
        "        self._attack_mode = \"targeted\"\n",
        "        self._targeted = 1\n",
        "        if target_map_function is None:\n",
        "            self._target_map_function = lambda images, labels:labels\n",
        "        else:\n",
        "            self._target_map_function = target_map_function\n",
        "        self._transform_label = self._get_target_label\n",
        "        \n",
        "        \n",
        "    def set_mode_least_likely(self, kth_min=1):\n",
        "        r\"\"\"\n",
        "        Set attack mode as least likely mode.\n",
        "  \n",
        "        Arguments:\n",
        "            kth_min (str): k-th smallest probability used as target labels (DEFAULT: 1)\n",
        "\n",
        "        \"\"\"\n",
        "        if self._attack_mode == 'only_default':\n",
        "            raise ValueError(\"Changing attack mode is not supported in this attack method.\")\n",
        "            \n",
        "        self._attack_mode = \"least_likely\"\n",
        "        self._targeted = 1\n",
        "        self._transform_label = self._get_least_likely_label\n",
        "        self._kth_min = kth_min\n",
        "        \n",
        "        \n",
        "    def set_return_type(self, type):\n",
        "        r\"\"\"\n",
        "        Set the return type of adversarial images: `int` or `float`.\n",
        "\n",
        "        Arguments:\n",
        "            type (str): 'float' or 'int'. (DEFAULT: 'float')\n",
        "\n",
        "        \"\"\"\n",
        "        if type == 'float':\n",
        "            self._return_type = 'float'\n",
        "        elif type == 'int':\n",
        "            self._return_type = 'int'\n",
        "        else:\n",
        "            raise ValueError(type + \" is not a valid type. [Options: float, int]\")\n",
        "\n",
        "    def save(self, data_loader, save_path=None, verbose=True):\n",
        "        r\"\"\"\n",
        "        Save adversarial images as torch.tensor from given torch.utils.data.DataLoader.\n",
        "\n",
        "        Arguments:\n",
        "            save_path (str): save_path.\n",
        "            data_loader (torch.utils.data.DataLoader): data loader.\n",
        "            verbose (bool): True for displaying detailed information. (DEFAULT: True)\n",
        "\n",
        "        \"\"\"\n",
        "        if (self._attack_mode == 'targeted') and (self._target_map_function == None):\n",
        "            raise ValueError(\"save is not supported for target_map_function=None\")\n",
        "        \n",
        "        image_list = []\n",
        "        label_list = []\n",
        "\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        l2_distance = []\n",
        "        \n",
        "        total_batch = len(data_loader)\n",
        "\n",
        "        for step, (images, labels) in enumerate(data_loader):\n",
        "            adv_images = self.__call__(images, labels)\n",
        "\n",
        "            batch_size = len(images)\n",
        "            image_list.append(adv_images.cpu())\n",
        "            label_list.append(labels.cpu())\n",
        "\n",
        "            if self._return_type == 'int':\n",
        "                adv_images = adv_images.float()/255\n",
        "\n",
        "            if verbose:\n",
        "                with torch.no_grad():\n",
        "                    self.model.eval()\n",
        "                    outputs = self.model(adv_images)\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    total += labels.size(0)\n",
        "                    right_idx = (predicted == labels.to(self.device))\n",
        "                    correct += right_idx.sum()\n",
        "                    \n",
        "                    delta = (adv_images - images.to(self.device)).view(batch_size, -1)\n",
        "                    l2_distance.append(torch.norm(delta[~right_idx], p=2, dim=1))                    \n",
        "                    acc = 100 * float(correct) / total\n",
        "                    print('- Save Progress: %2.2f %% / Accuracy: %2.2f %% / L2: %1.5f' \\\n",
        "                          % ((step+1)/total_batch*100, acc, torch.cat(l2_distance).mean()), end='\\r')\n",
        "\n",
        "        x = torch.cat(image_list, 0)\n",
        "        y = torch.cat(label_list, 0)\n",
        "        \n",
        "        if save_path is not None:\n",
        "            torch.save((x, y), save_path)\n",
        "            print('\\n- Save Complete!')\n",
        "\n",
        "        self._switch_model()\n",
        "        \n",
        "    def _get_label(self, images, labels):\n",
        "        r\"\"\"\n",
        "        Function for changing the attack mode.\n",
        "        Return input labels.\n",
        "        \"\"\"\n",
        "        return labels\n",
        "    \n",
        "    def _get_target_label(self, images, labels):\n",
        "        r\"\"\"\n",
        "        Function for changing the attack mode.\n",
        "        Return input labels.\n",
        "        \"\"\"\n",
        "        return self._target_map_function(images, labels)\n",
        "    \n",
        "    def _get_least_likely_label(self, images, labels):\n",
        "        r\"\"\"\n",
        "        Function for changing the attack mode.\n",
        "        Return least likely labels.\n",
        "        \"\"\"\n",
        "        outputs = self.model(images)\n",
        "        if self._kth_min < 0:\n",
        "            pos = outputs.shape[1] + self._kth_min + 1\n",
        "        else:\n",
        "            pos = self._kth_min\n",
        "        _, labels = torch.kthvalue(outputs.data, pos)\n",
        "        labels = labels.detach_()\n",
        "        return labels\n",
        "    \n",
        "    def _to_uint(self, images):\n",
        "        r\"\"\"\n",
        "        Function for changing the return type.\n",
        "        Return images as int.\n",
        "        \"\"\"\n",
        "        return (images*255).type(torch.uint8)\n",
        "\n",
        "    def _switch_model(self):\n",
        "        r\"\"\"\n",
        "        Function for changing the training mode of the model.\n",
        "        \"\"\"\n",
        "        if self.training:\n",
        "            self.model.train()\n",
        "        else:\n",
        "            self.model.eval()\n",
        "\n",
        "    def __str__(self):\n",
        "        info = self.__dict__.copy()\n",
        "        \n",
        "        del_keys = ['model', 'attack']\n",
        "        \n",
        "        for key in info.keys():\n",
        "            if key[0] == \"_\":\n",
        "                del_keys.append(key)\n",
        "                \n",
        "        for key in del_keys:\n",
        "            del info[key]\n",
        "        \n",
        "        info['attack_mode'] = self._attack_mode\n",
        "        if info['attack_mode'] == 'only_default':\n",
        "            info['attack_mode'] = 'default'\n",
        "            \n",
        "        info['return_type'] = self._return_type\n",
        "        \n",
        "        return self.attack + \"(\" + ', '.join('{}={}'.format(key, val) for key, val in info.items()) + \")\"\n",
        "\n",
        "    def __call__(self, *input, **kwargs):\n",
        "        self.model.eval()\n",
        "        images = self.forward(*input, **kwargs)\n",
        "        self._switch_model()\n",
        "\n",
        "        if self._return_type == 'int':\n",
        "            images = self._to_uint(images)\n",
        "\n",
        "        return images\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBRbXJ96JJuU"
      },
      "source": [
        "##PGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzhyD1Cfq5Lc"
      },
      "source": [
        "class PGD(Attack):\n",
        "    r\"\"\"\n",
        "    PGD in the paper 'Towards Deep Learning Models Resistant to Adversarial Attacks'\n",
        "    [https://arxiv.org/abs/1706.06083]\n",
        "    \n",
        "    Distance Measure : Linf\n",
        "\n",
        "    Arguments:\n",
        "        model (nn.Module): model to attack.\n",
        "        eps (float): maximum perturbation. (DEFALUT: 0.3)\n",
        "        alpha (float): step size. (DEFALUT: 2/255)\n",
        "        steps (int): number of steps. (DEFALUT: 40)\n",
        "        random_start (bool): using random initialization of delta. (DEFAULT: False)\n",
        "        \n",
        "    Shape:\n",
        "        - images: :math:`(N, C, H, W)` where `N = number of batches`, `C = number of channels`,        `H = height` and `W = width`. It must have a range [0, 1].\n",
        "        - labels: :math:`(N)` where each value :math:`y_i` is :math:`0 \\leq y_i \\leq` `number of labels`.\n",
        "        - output: :math:`(N, C, H, W)`.\n",
        "          \n",
        "    Examples::\n",
        "        >>> attack = torchattacks.PGD(model, eps=8/255, alpha=1/255, steps=40, random_start=False)\n",
        "        >>> adv_images = attack(images, labels)\n",
        "        \n",
        "    \"\"\"\n",
        "    def __init__(self, model, eps=0.3, alpha=2/255, steps=40, random_start=False):\n",
        "        super(PGD, self).__init__(\"PGD\", model)\n",
        "        self.eps = eps\n",
        "        self.alpha = alpha\n",
        "        self.steps = steps\n",
        "        self.random_start = random_start\n",
        "\n",
        "    def forward(self, images, labels):\n",
        "        \"\"\"\n",
        "        Overridden.\n",
        "        \"\"\"\n",
        "        images = images.clone().detach().to(self.device)\n",
        "        labels = labels.clone().detach().to(self.device)\n",
        "        labels = self._transform_label(images, labels)\n",
        "        \n",
        "        loss = nn.CrossEntropyLoss()\n",
        "\n",
        "        adv_images = images.clone().detach()\n",
        "\n",
        "        if self.random_start:\n",
        "            # Starting at a uniformly random point\n",
        "            adv_images = adv_images + torch.empty_like(adv_images).uniform_(-self.eps, self.eps)\n",
        "            adv_images = torch.clamp(adv_images, min=0, max=1).detach()\n",
        "\n",
        "        for i in range(self.steps):\n",
        "            adv_images.requires_grad = True\n",
        "            outputs = self.model(adv_images)\n",
        "\n",
        "            cost = self._targeted*loss(outputs, labels)\n",
        "\n",
        "            grad = torch.autograd.grad(cost, adv_images,\n",
        "                                       retain_graph=False, create_graph=False)[0]\n",
        "\n",
        "            adv_images = adv_images.detach() - self.alpha*grad.sign()\n",
        "            delta = torch.clamp(adv_images - images, min=-self.eps, max=self.eps)\n",
        "            adv_images = torch.clamp(images + delta, min=0, max=1).detach()\n",
        "\n",
        "        return adv_images\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wAOus0aJOAR"
      },
      "source": [
        "##FAB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GE6acwcMBbCW"
      },
      "source": [
        "from __future__ import division\n",
        "from __future__ import unicode_literals\n",
        "\n",
        "DEFAULT_EPS_DICT_BY_NORM = {'Linf': .3, 'L2': 1., 'L1': 5.0}\n",
        "\n",
        "class FAB(Attack):\n",
        "    r\"\"\"\n",
        "    Fast Adaptive Boundary Attack in the paper 'Minimally distorted Adversarial Examples with a Fast Adaptive Boundary Attack'\n",
        "    [https://arxiv.org/abs/1907.02044]\n",
        "    [https://github.com/fra31/auto-attack]\n",
        "    \n",
        "    Distance Measure : Linf, L2, L1\n",
        "\n",
        "    Arguments:\n",
        "        model (nn.Module): model to attack.\n",
        "        norm (str) : Lp-norm to minimize. ('Linf', 'L2', 'L1' supported, DEFALUT: 'Linf')\n",
        "        eps (float): maximum perturbation. (DEFALUT: None)\n",
        "        steps (int): number of steps. (DEFALUT: 100)\n",
        "        n_restarts (int): number of random restarts. (DEFALUT: 1)\n",
        "        alpha_max (float): alpha_max. (DEFALUT: 0.1)\n",
        "        eta (float): overshooting. (DEFALUT: 1.05)\n",
        "        beta (float): backward step. (DEFALUT: 0.9)\n",
        "        verbose (bool): print progress. (DEFAULT: False)\n",
        "        seed (int): random seed for the starting point. (DEFAULT: 0)\n",
        "        targeted (bool): targeted attack for every wrong classes. (DEFAULT: False)\n",
        "        n_classes (int): number of classes. (DEFAULT: 10)\n",
        "        \n",
        "    Shape:\n",
        "        - images: :math:`(N, C, H, W)` where `N = number of batches`, `C = number of channels`,        `H = height` and `W = width`. It must have a range [0, 1].\n",
        "        - labels: :math:`(N)` where each value :math:`y_i` is :math:`0 \\leq y_i \\leq` `number of labels`.\n",
        "        - output: :math:`(N, C, H, W)`.\n",
        "          \n",
        "    Examples::\n",
        "        >>> attack = torchattacks.FAB(model, norm='Linf', steps=100, eps=None, n_restarts=1, alpha_max=0.1, eta=1.05, beta=0.9, loss_fn=None, verbose=False, seed=0, targeted=False, n_classes=10)\n",
        "        >>> adv_images = attack(images, labels)\n",
        "        \n",
        "    \"\"\"\n",
        "    def __init__(self, model, norm='Linf', eps=None, steps=100, n_restarts=1,\n",
        "                 alpha_max=0.1, eta=1.05, beta=0.9, verbose=False, seed=0,\n",
        "                 targeted=False, n_classes=10):\n",
        "        super(FAB, self).__init__(\"FAB\", model)\n",
        "        self.norm = norm\n",
        "        self.n_restarts = n_restarts\n",
        "        self.eps = eps if eps is not None else DEFAULT_EPS_DICT_BY_NORM[norm]\n",
        "        self.alpha_max = alpha_max\n",
        "        self.eta = eta\n",
        "        self.beta = beta\n",
        "        self.steps = steps\n",
        "        self.targeted = False\n",
        "        self.verbose = verbose\n",
        "        self.seed = seed\n",
        "        self.target_class = None\n",
        "        self.n_target_classes = n_classes - 1\n",
        "        self._attack_mode = 'only_default'\n",
        "\n",
        "    def forward(self, images, labels):\n",
        "        r\"\"\"\n",
        "        Overridden.\n",
        "        \"\"\"\n",
        "        images = images.clone().detach().to(self.device)\n",
        "        labels = labels.clone().detach().to(self.device)\n",
        "        adv_images = self.perturb(images, labels)\n",
        "\n",
        "        return adv_images\n",
        "    \n",
        "    def _get_predicted_label(self, x):\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(x)\n",
        "        _, y = torch.max(outputs, dim=1)\n",
        "        return y\n",
        "\n",
        "    def check_shape(self, x):\n",
        "        return x if len(x.shape) > 0 else x.unsqueeze(0)\n",
        "\n",
        "    def get_diff_logits_grads_batch(self, imgs, la):\n",
        "        im = imgs.clone().requires_grad_()\n",
        "        with torch.enable_grad():\n",
        "            y = self.model(im)\n",
        "\n",
        "        g2 = torch.zeros([y.shape[-1], *imgs.size()]).to(self.device)\n",
        "        grad_mask = torch.zeros_like(y)\n",
        "        for counter in range(y.shape[-1]):\n",
        "            zero_gradients(im)\n",
        "            grad_mask[:, counter] = 1.0\n",
        "            y.backward(grad_mask, retain_graph=True)\n",
        "            grad_mask[:, counter] = 0.0\n",
        "            g2[counter] = im.grad.data\n",
        "\n",
        "        g2 = torch.transpose(g2, 0, 1).detach()\n",
        "        #y2 = self.model(imgs).detach()\n",
        "        y2 = y.detach()\n",
        "        df = y2 - y2[torch.arange(imgs.shape[0]), la].unsqueeze(1)\n",
        "        dg = g2 - g2[torch.arange(imgs.shape[0]), la].unsqueeze(1)\n",
        "        df[torch.arange(imgs.shape[0]), la] = 1e10\n",
        "\n",
        "        return df, dg\n",
        "\n",
        "    def get_diff_logits_grads_batch_targeted(self, imgs, la, la_target):\n",
        "        u = torch.arange(imgs.shape[0])\n",
        "        im = imgs.clone().requires_grad_()\n",
        "        with torch.enable_grad():\n",
        "            y = self.model(im)\n",
        "            diffy = -(y[u, la] - y[u, la_target])\n",
        "            sumdiffy = diffy.sum()\n",
        "\n",
        "        zero_gradients(im)\n",
        "        sumdiffy.backward()\n",
        "        graddiffy = im.grad.data\n",
        "        df = diffy.detach().unsqueeze(1)\n",
        "        dg = graddiffy.unsqueeze(1)\n",
        "\n",
        "        return df, dg\n",
        "\n",
        "    def attack_single_run(self, x, y=None, use_rand_start=False):\n",
        "        \"\"\"\n",
        "        :param x:    clean images\n",
        "        :param y:    clean labels, if None we use the predicted labels\n",
        "        \"\"\"\n",
        "\n",
        "        #self.device = x.device\n",
        "        self.orig_dim = list(x.shape[1:])\n",
        "        self.ndims = len(self.orig_dim)\n",
        "\n",
        "        x = x.detach().clone().float().to(self.device)\n",
        "        #assert next(self.model.parameters()).device == x.device\n",
        "\n",
        "        y_pred = self._get_predicted_label(x)\n",
        "        if y is None:\n",
        "            y = y_pred.detach().clone().long().to(self.device)\n",
        "        else:\n",
        "            y = y.detach().clone().long().to(self.device)\n",
        "        pred = y_pred == y\n",
        "        corr_classified = pred.float().sum()\n",
        "        if self.verbose:\n",
        "            print('Clean accuracy: {:.2%}'.format(pred.float().mean()))\n",
        "        if pred.sum() == 0:\n",
        "            return x\n",
        "        pred = self.check_shape(pred.nonzero().squeeze())\n",
        "\n",
        "        startt = time.time()\n",
        "        # runs the attack only on correctly classified points\n",
        "        im2 = x[pred].detach().clone()\n",
        "        la2 = y[pred].detach().clone()\n",
        "        if len(im2.shape) == self.ndims:\n",
        "            im2 = im2.unsqueeze(0)\n",
        "        bs = im2.shape[0]\n",
        "        u1 = torch.arange(bs)\n",
        "        adv = im2.clone()\n",
        "        adv_c = x.clone()\n",
        "        res2 = 1e10 * torch.ones([bs]).to(self.device)\n",
        "        res_c = torch.zeros([x.shape[0]]).to(self.device)\n",
        "        x1 = im2.clone()\n",
        "        x0 = im2.clone().reshape([bs, -1])\n",
        "        counter_restarts = 0\n",
        "\n",
        "        while counter_restarts < 1:\n",
        "            if use_rand_start:\n",
        "                if self.norm == 'Linf':\n",
        "                    t = 2 * torch.rand(x1.shape).to(self.device) - 1\n",
        "                    x1 = im2 + (torch.min(res2,\n",
        "                                          self.eps * torch.ones(res2.shape)\n",
        "                                          .to(self.device)\n",
        "                                          ).reshape([-1, *[1]*self.ndims])\n",
        "                                ) * t / (t.reshape([t.shape[0], -1]).abs()\n",
        "                                         .max(dim=1, keepdim=True)[0]\n",
        "                                         .reshape([-1, *[1]*self.ndims])) * .5\n",
        "                elif self.norm == 'L2':\n",
        "                    t = torch.randn(x1.shape).to(self.device)\n",
        "                    x1 = im2 + (torch.min(res2,\n",
        "                                          self.eps * torch.ones(res2.shape)\n",
        "                                          .to(self.device)\n",
        "                                          ).reshape([-1, *[1]*self.ndims])\n",
        "                                ) * t / ((t ** 2)\n",
        "                                         .view(t.shape[0], -1)\n",
        "                                         .sum(dim=-1)\n",
        "                                         .sqrt()\n",
        "                                         .view(t.shape[0], *[1]*self.ndims)) * .5\n",
        "                elif self.norm == 'L1':\n",
        "                    t = torch.randn(x1.shape).to(self.device)\n",
        "                    x1 = im2 + (torch.min(res2,\n",
        "                                          self.eps * torch.ones(res2.shape)\n",
        "                                          .to(self.device)\n",
        "                                          ).reshape([-1, *[1]*self.ndims])\n",
        "                                ) * t / (t.abs().view(t.shape[0], -1)\n",
        "                                         .sum(dim=-1)\n",
        "                                         .view(t.shape[0], *[1]*self.ndims)) / 2\n",
        "\n",
        "                x1 = x1.clamp(0.0, 1.0)\n",
        "\n",
        "            counter_iter = 0\n",
        "            while counter_iter < self.steps:\n",
        "                with torch.no_grad():\n",
        "                    df, dg = self.get_diff_logits_grads_batch(x1, la2)\n",
        "                    if self.norm == 'Linf':\n",
        "                        dist1 = df.abs() / (1e-12 +\n",
        "                                            dg.abs()\n",
        "                                            .view(dg.shape[0], dg.shape[1], -1)\n",
        "                                            .sum(dim=-1))\n",
        "                    elif self.norm == 'L2':\n",
        "                        dist1 = df.abs() / (1e-12 + (dg ** 2)\n",
        "                                            .view(dg.shape[0], dg.shape[1], -1)\n",
        "                                            .sum(dim=-1).sqrt())\n",
        "                    elif self.norm == 'L1':\n",
        "                        dist1 = df.abs() / (1e-12 + dg.abs().reshape(\n",
        "                            [df.shape[0], df.shape[1], -1]).max(dim=2)[0])\n",
        "                    else:\n",
        "                        raise ValueError('norm not supported')\n",
        "                    ind = dist1.min(dim=1)[1]\n",
        "                    dg2 = dg[u1, ind]\n",
        "                    b = (- df[u1, ind] + (dg2 * x1).view(x1.shape[0], -1)\n",
        "                                         .sum(dim=-1))\n",
        "                    w = dg2.reshape([bs, -1])\n",
        "\n",
        "                    if self.norm == 'Linf':\n",
        "                        d3 = projection_linf(\n",
        "                            torch.cat((x1.reshape([bs, -1]), x0), 0),\n",
        "                            torch.cat((w, w), 0),\n",
        "                            torch.cat((b, b), 0))\n",
        "                    elif self.norm == 'L2':\n",
        "                        d3 = projection_l2(\n",
        "                            torch.cat((x1.reshape([bs, -1]), x0), 0),\n",
        "                            torch.cat((w, w), 0),\n",
        "                            torch.cat((b, b), 0))\n",
        "                    elif self.norm == 'L1':\n",
        "                        d3 = projection_l1(\n",
        "                            torch.cat((x1.reshape([bs, -1]), x0), 0),\n",
        "                            torch.cat((w, w), 0),\n",
        "                            torch.cat((b, b), 0))\n",
        "                    d1 = torch.reshape(d3[:bs], x1.shape)\n",
        "                    d2 = torch.reshape(d3[-bs:], x1.shape)\n",
        "                    if self.norm == 'Linf':\n",
        "                        a0 = d3.abs().max(dim=1, keepdim=True)[0]\\\n",
        "                            .view(-1, *[1]*self.ndims)\n",
        "                    elif self.norm == 'L2':\n",
        "                        a0 = (d3 ** 2).sum(dim=1, keepdim=True).sqrt()\\\n",
        "                            .view(-1, *[1]*self.ndims)\n",
        "                    elif self.norm == 'L1':\n",
        "                        a0 = d3.abs().sum(dim=1, keepdim=True)\\\n",
        "                            .view(-1, *[1]*self.ndims)\n",
        "                    a0 = torch.max(a0, 1e-8 * torch.ones(\n",
        "                        a0.shape).to(self.device))\n",
        "                    a1 = a0[:bs]\n",
        "                    a2 = a0[-bs:]\n",
        "                    alpha = torch.min(torch.max(a1 / (a1 + a2),\n",
        "                                                torch.zeros(a1.shape)\n",
        "                                                .to(self.device)),\n",
        "                                      self.alpha_max * torch.ones(a1.shape)\n",
        "                                      .to(self.device))\n",
        "                    x1 = ((x1 + self.eta * d1) * (1 - alpha) +\n",
        "                          (im2 + d2 * self.eta) * alpha).clamp(0.0, 1.0)\n",
        "\n",
        "                    is_adv = self._get_predicted_label(x1) != la2\n",
        "\n",
        "                    if is_adv.sum() > 0:\n",
        "                        ind_adv = is_adv.nonzero().squeeze()\n",
        "                        ind_adv = self.check_shape(ind_adv)\n",
        "                        if self.norm == 'Linf':\n",
        "                            t = (x1[ind_adv] - im2[ind_adv]).reshape(\n",
        "                                [ind_adv.shape[0], -1]).abs().max(dim=1)[0]\n",
        "                        elif self.norm == 'L2':\n",
        "                            t = ((x1[ind_adv] - im2[ind_adv]) ** 2)\\\n",
        "                                .view(ind_adv.shape[0], -1).sum(dim=-1).sqrt()\n",
        "                        elif self.norm == 'L1':\n",
        "                            t = (x1[ind_adv] - im2[ind_adv])\\\n",
        "                                .abs().view(ind_adv.shape[0], -1).sum(dim=-1)\n",
        "                        adv[ind_adv] = x1[ind_adv] * (t < res2[ind_adv]).\\\n",
        "                            float().reshape([-1, *[1]*self.ndims]) + adv[ind_adv]\\\n",
        "                            * (t >= res2[ind_adv]).float().reshape(\n",
        "                            [-1, *[1]*self.ndims])\n",
        "                        res2[ind_adv] = t * (t < res2[ind_adv]).float()\\\n",
        "                            + res2[ind_adv] * (t >= res2[ind_adv]).float()\n",
        "                        x1[ind_adv] = im2[ind_adv] + (\n",
        "                            x1[ind_adv] - im2[ind_adv]) * self.beta\n",
        "\n",
        "                    counter_iter += 1\n",
        "\n",
        "            counter_restarts += 1\n",
        "\n",
        "        ind_succ = res2 < 1e10\n",
        "        if self.verbose:\n",
        "            print('success rate: {:.0f}/{:.0f}'\n",
        "                  .format(ind_succ.float().sum(), corr_classified) +\n",
        "                  ' (on correctly classified points) in {:.1f} s'\n",
        "                  .format(time.time() - startt))\n",
        "\n",
        "        res_c[pred] = res2 * ind_succ.float() + 1e10 * (1 - ind_succ.float())\n",
        "        ind_succ = self.check_shape(ind_succ.nonzero().squeeze())\n",
        "        adv_c[pred[ind_succ]] = adv[ind_succ].clone()\n",
        "\n",
        "        return adv_c\n",
        "\n",
        "    def attack_single_run_targeted(self, x, y=None, use_rand_start=False):\n",
        "        \"\"\"\n",
        "        :param x:    clean images\n",
        "        :param y:    clean labels, if None we use the predicted labels\n",
        "        \"\"\"\n",
        "\n",
        "        if self.device is None:\n",
        "            self.device = x.device\n",
        "        self.orig_dim = list(x.shape[1:])\n",
        "        self.ndims = len(self.orig_dim)\n",
        "\n",
        "        x = x.detach().clone().float().to(self.device)\n",
        "        #assert next(self.model.parameters()).device == x.device\n",
        "\n",
        "        y_pred = self._get_predicted_label(x)\n",
        "        if y is None:\n",
        "            y = y_pred.detach().clone().long().to(self.device)\n",
        "        else:\n",
        "            y = y.detach().clone().long().to(self.device)\n",
        "        pred = y_pred == y\n",
        "        corr_classified = pred.float().sum()\n",
        "        if self.verbose:\n",
        "            print('Clean accuracy: {:.2%}'.format(pred.float().mean()))\n",
        "        if pred.sum() == 0:\n",
        "            return x\n",
        "        pred = self.check_shape(pred.nonzero().squeeze())\n",
        "\n",
        "        output = self.model(x)\n",
        "        la_target = output.sort(dim=-1)[1][:, -self.target_class]\n",
        "\n",
        "        startt = time.time()\n",
        "        # runs the attack only on correctly classified points\n",
        "        im2 = x[pred].detach().clone()\n",
        "        la2 = y[pred].detach().clone()\n",
        "        la_target2 = la_target[pred].detach().clone()\n",
        "        if len(im2.shape) == self.ndims:\n",
        "            im2 = im2.unsqueeze(0)\n",
        "        bs = im2.shape[0]\n",
        "        u1 = torch.arange(bs)\n",
        "        adv = im2.clone()\n",
        "        adv_c = x.clone()\n",
        "        res2 = 1e10 * torch.ones([bs]).to(self.device)\n",
        "        res_c = torch.zeros([x.shape[0]]).to(self.device)\n",
        "        x1 = im2.clone()\n",
        "        x0 = im2.clone().reshape([bs, -1])\n",
        "        counter_restarts = 0\n",
        "\n",
        "        while counter_restarts < 1:\n",
        "            if use_rand_start:\n",
        "                if self.norm == 'Linf':\n",
        "                    t = 2 * torch.rand(x1.shape).to(self.device) - 1\n",
        "                    x1 = im2 + (torch.min(res2,\n",
        "                                          self.eps * torch.ones(res2.shape)\n",
        "                                          .to(self.device)\n",
        "                                          ).reshape([-1, *[1]*self.ndims])\n",
        "                                ) * t / (t.reshape([t.shape[0], -1]).abs()\n",
        "                                         .max(dim=1, keepdim=True)[0]\n",
        "                                         .reshape([-1, *[1]*self.ndims])) * .5\n",
        "                elif self.norm == 'L2':\n",
        "                    t = torch.randn(x1.shape).to(self.device)\n",
        "                    x1 = im2 + (torch.min(res2,\n",
        "                                          self.eps * torch.ones(res2.shape)\n",
        "                                          .to(self.device)\n",
        "                                          ).reshape([-1, *[1]*self.ndims])\n",
        "                                ) * t / ((t ** 2)\n",
        "                                         .view(t.shape[0], -1)\n",
        "                                         .sum(dim=-1)\n",
        "                                         .sqrt()\n",
        "                                         .view(t.shape[0], *[1]*self.ndims)) * .5\n",
        "                elif self.norm == 'L1':\n",
        "                    t = torch.randn(x1.shape).to(self.device)\n",
        "                    x1 = im2 + (torch.min(res2,\n",
        "                                          self.eps * torch.ones(res2.shape)\n",
        "                                          .to(self.device)\n",
        "                                          ).reshape([-1, *[1]*self.ndims])\n",
        "                                ) * t / (t.abs().view(t.shape[0], -1)\n",
        "                                         .sum(dim=-1)\n",
        "                                         .view(t.shape[0], *[1]*self.ndims)) / 2\n",
        "\n",
        "                x1 = x1.clamp(0.0, 1.0)\n",
        "\n",
        "            counter_iter = 0\n",
        "            while counter_iter < self.steps:\n",
        "                with torch.no_grad():\n",
        "                    df, dg = self.get_diff_logits_grads_batch_targeted(x1, la2, la_target2)\n",
        "                    if self.norm == 'Linf':\n",
        "                        dist1 = df.abs() / (1e-12 +\n",
        "                                            dg.abs()\n",
        "                                            .view(dg.shape[0], dg.shape[1], -1)\n",
        "                                            .sum(dim=-1))\n",
        "                    elif self.norm == 'L2':\n",
        "                        dist1 = df.abs() / (1e-12 + (dg ** 2)\n",
        "                                            .view(dg.shape[0], dg.shape[1], -1)\n",
        "                                            .sum(dim=-1).sqrt())\n",
        "                    elif self.norm == 'L1':\n",
        "                        dist1 = df.abs() / (1e-12 + dg.abs().reshape(\n",
        "                            [df.shape[0], df.shape[1], -1]).max(dim=2)[0])\n",
        "                    else:\n",
        "                        raise ValueError('norm not supported')\n",
        "                    ind = dist1.min(dim=1)[1]\n",
        "                    #print(ind)\n",
        "                    dg2 = dg[u1, ind]\n",
        "                    b = (- df[u1, ind] + (dg2 * x1).view(x1.shape[0], -1)\n",
        "                                         .sum(dim=-1))\n",
        "                    w = dg2.reshape([bs, -1])\n",
        "\n",
        "                    if self.norm == 'Linf':\n",
        "                        d3 = projection_linf(\n",
        "                            torch.cat((x1.reshape([bs, -1]), x0), 0),\n",
        "                            torch.cat((w, w), 0),\n",
        "                            torch.cat((b, b), 0))\n",
        "                    elif self.norm == 'L2':\n",
        "                        d3 = projection_l2(\n",
        "                            torch.cat((x1.reshape([bs, -1]), x0), 0),\n",
        "                            torch.cat((w, w), 0),\n",
        "                            torch.cat((b, b), 0))\n",
        "                    elif self.norm == 'L1':\n",
        "                        d3 = projection_l1(\n",
        "                            torch.cat((x1.reshape([bs, -1]), x0), 0),\n",
        "                            torch.cat((w, w), 0),\n",
        "                            torch.cat((b, b), 0))\n",
        "                    d1 = torch.reshape(d3[:bs], x1.shape)\n",
        "                    d2 = torch.reshape(d3[-bs:], x1.shape)\n",
        "                    if self.norm == 'Linf':\n",
        "                        a0 = d3.abs().max(dim=1, keepdim=True)[0]\\\n",
        "                            .view(-1, *[1]*self.ndims)\n",
        "                    elif self.norm == 'L2':\n",
        "                        a0 = (d3 ** 2).sum(dim=1, keepdim=True).sqrt()\\\n",
        "                            .view(-1, *[1]*self.ndims)\n",
        "                    elif self.norm == 'L1':\n",
        "                        a0 = d3.abs().sum(dim=1, keepdim=True)\\\n",
        "                            .view(-1, *[1]*self.ndims)\n",
        "                    a0 = torch.max(a0, 1e-8 * torch.ones(\n",
        "                        a0.shape).to(self.device))\n",
        "                    a1 = a0[:bs]\n",
        "                    a2 = a0[-bs:]\n",
        "                    alpha = torch.min(torch.max(a1 / (a1 + a2),\n",
        "                                                torch.zeros(a1.shape)\n",
        "                                                .to(self.device)),\n",
        "                                      self.alpha_max * torch.ones(a1.shape)\n",
        "                                      .to(self.device))\n",
        "                    x1 = ((x1 + self.eta * d1) * (1 - alpha) +\n",
        "                          (im2 + d2 * self.eta) * alpha).clamp(0.0, 1.0)\n",
        "\n",
        "                    is_adv = self._get_predicted_label(x1) != la2\n",
        "\n",
        "                    if is_adv.sum() > 0:\n",
        "                        ind_adv = is_adv.nonzero().squeeze()\n",
        "                        ind_adv = self.check_shape(ind_adv)\n",
        "                        if self.norm == 'Linf':\n",
        "                            t = (x1[ind_adv] - im2[ind_adv]).reshape(\n",
        "                                [ind_adv.shape[0], -1]).abs().max(dim=1)[0]\n",
        "                        elif self.norm == 'L2':\n",
        "                            t = ((x1[ind_adv] - im2[ind_adv]) ** 2)\\\n",
        "                                .view(ind_adv.shape[0], -1).sum(dim=-1).sqrt()\n",
        "                        elif self.norm == 'L1':\n",
        "                            t = (x1[ind_adv] - im2[ind_adv])\\\n",
        "                                .abs().view(ind_adv.shape[0], -1).sum(dim=-1)\n",
        "                        adv[ind_adv] = x1[ind_adv] * (t < res2[ind_adv]).\\\n",
        "                            float().reshape([-1, *[1]*self.ndims]) + adv[ind_adv]\\\n",
        "                            * (t >= res2[ind_adv]).float().reshape(\n",
        "                            [-1, *[1]*self.ndims])\n",
        "                        res2[ind_adv] = t * (t < res2[ind_adv]).float()\\\n",
        "                            + res2[ind_adv] * (t >= res2[ind_adv]).float()\n",
        "                        x1[ind_adv] = im2[ind_adv] + (\n",
        "                            x1[ind_adv] - im2[ind_adv]) * self.beta\n",
        "\n",
        "                    counter_iter += 1\n",
        "\n",
        "            counter_restarts += 1\n",
        "\n",
        "        ind_succ = res2 < 1e10\n",
        "        if self.verbose:\n",
        "            print('success rate: {:.0f}/{:.0f}'\n",
        "                  .format(ind_succ.float().sum(), corr_classified) +\n",
        "                  ' (on correctly classified points) in {:.1f} s'\n",
        "                  .format(time.time() - startt))\n",
        "\n",
        "        res_c[pred] = res2 * ind_succ.float() + 1e10 * (1 - ind_succ.float())\n",
        "        ind_succ = self.check_shape(ind_succ.nonzero().squeeze())\n",
        "        adv_c[pred[ind_succ]] = adv[ind_succ].clone()\n",
        "\n",
        "        return adv_c\n",
        "\n",
        "    def perturb(self, x, y):\n",
        "        adv = x.clone()\n",
        "        with torch.no_grad():\n",
        "            acc = self.model(x).max(1)[1] == y\n",
        "\n",
        "            startt = time.time()\n",
        "\n",
        "            torch.random.manual_seed(self.seed)\n",
        "            torch.cuda.random.manual_seed(self.seed)\n",
        "\n",
        "            if not self.targeted:\n",
        "                for counter in range(self.n_restarts):\n",
        "                    ind_to_fool = acc.nonzero().squeeze()\n",
        "                    if len(ind_to_fool.shape) == 0: ind_to_fool = ind_to_fool.unsqueeze(0)\n",
        "                    if ind_to_fool.numel() != 0:\n",
        "                        x_to_fool, y_to_fool = x[ind_to_fool].clone(), y[ind_to_fool].clone()\n",
        "                        adv_curr = self.attack_single_run(x_to_fool, y_to_fool, use_rand_start=(counter > 0))\n",
        "\n",
        "                        acc_curr = self.model(adv_curr).max(1)[1] == y_to_fool\n",
        "                        if self.norm == 'Linf':\n",
        "                            res = (x_to_fool - adv_curr).abs().view(x_to_fool.shape[0], -1).max(1)[0]\n",
        "                        elif self.norm == 'L2':\n",
        "                            res = ((x_to_fool - adv_curr) ** 2).view(x_to_fool.shape[0], -1).sum(dim=-1).sqrt()\n",
        "                        acc_curr = torch.max(acc_curr, res > self.eps)\n",
        "\n",
        "                        ind_curr = (acc_curr == 0).nonzero().squeeze()\n",
        "                        acc[ind_to_fool[ind_curr]] = 0\n",
        "                        adv[ind_to_fool[ind_curr]] = adv_curr[ind_curr].clone()\n",
        "\n",
        "                        if self.verbose:\n",
        "                            print('restart {} - robust accuracy: {:.2%} at eps = {:.5f} - cum. time: {:.1f} s'.format(\n",
        "                                counter, acc.float().mean(), self.eps, time.time() - startt))\n",
        "\n",
        "            else:\n",
        "                for target_class in range(2, self.n_target_classes + 2):\n",
        "                    self.target_class = target_class\n",
        "                    for counter in range(self.n_restarts):\n",
        "                        ind_to_fool = acc.nonzero().squeeze()\n",
        "                        if len(ind_to_fool.shape) == 0: ind_to_fool = ind_to_fool.unsqueeze(0)\n",
        "                        if ind_to_fool.numel() != 0:\n",
        "                            x_to_fool, y_to_fool = x[ind_to_fool].clone(), y[ind_to_fool].clone()\n",
        "                            adv_curr = self.attack_single_run_targeted(x_to_fool, y_to_fool, use_rand_start=(counter > 0))\n",
        "\n",
        "                            acc_curr = self.model(adv_curr).max(1)[1] == y_to_fool\n",
        "                            if self.norm == 'Linf':\n",
        "                                res = (x_to_fool - adv_curr).abs().view(x_to_fool.shape[0], -1).max(1)[0]\n",
        "                            elif self.norm == 'L2':\n",
        "                                res = ((x_to_fool - adv_curr) ** 2).view(x_to_fool.shape[0], -1).sum(dim=-1).sqrt()\n",
        "                            acc_curr = torch.max(acc_curr, res > self.eps)\n",
        "\n",
        "                            ind_curr = (acc_curr == 0).nonzero().squeeze()\n",
        "                            acc[ind_to_fool[ind_curr]] = 0\n",
        "                            adv[ind_to_fool[ind_curr]] = adv_curr[ind_curr].clone()\n",
        "\n",
        "                            if self.verbose:\n",
        "                                print('restart {} - target_class {} - robust accuracy: {:.2%} at eps = {:.5f} - cum. time: {:.1f} s'.format(\n",
        "                                    counter, self.target_class, acc.float().mean(), self.eps, time.time() - startt))\n",
        "\n",
        "        return adv\n",
        "        \n",
        "        \n",
        "######################################################\n",
        "#################### Utils ###########################\n",
        "######################################################\n",
        "        \n",
        "def projection_linf(points_to_project, w_hyperplane, b_hyperplane):\n",
        "    device = points_to_project.device\n",
        "    t, w, b = points_to_project, w_hyperplane.clone(), b_hyperplane.clone()\n",
        "\n",
        "    sign = 2 * ((w * t).sum(1) - b >= 0) - 1\n",
        "    w.mul_(sign.unsqueeze(1))\n",
        "    b.mul_(sign)\n",
        "\n",
        "    a = (w < 0).float()\n",
        "    d = (a - t) * (w != 0).float()\n",
        "\n",
        "    p = a - t * (2 * a - 1)\n",
        "    indp = torch.argsort(p, dim=1)\n",
        "\n",
        "    b = b - (w * t).sum(1)\n",
        "    b0 = (w * d).sum(1)\n",
        "\n",
        "    indp2 = indp.flip((1,))\n",
        "    ws = w.gather(1, indp2)\n",
        "    bs2 = - ws * d.gather(1, indp2)\n",
        "\n",
        "    s = torch.cumsum(ws.abs(), dim=1)\n",
        "    sb = torch.cumsum(bs2, dim=1) + b0.unsqueeze(1)\n",
        "\n",
        "    b2 = sb[:, -1] - s[:, -1] * p.gather(1, indp[:, 0:1]).squeeze(1)\n",
        "    c_l = b - b2 > 0\n",
        "    c2 = (b - b0 > 0) & (~c_l)\n",
        "    lb = torch.zeros(c2.sum(), device=device)\n",
        "    ub = torch.full_like(lb, w.shape[1] - 1)\n",
        "    nitermax = math.ceil(math.log2(w.shape[1]))\n",
        "\n",
        "    indp_, sb_, s_, p_, b_ = indp[c2], sb[c2], s[c2], p[c2], b[c2]\n",
        "    for counter in range(nitermax):\n",
        "        counter4 = torch.floor((lb + ub) / 2)\n",
        "\n",
        "        counter2 = counter4.long().unsqueeze(1)\n",
        "        indcurr = indp_.gather(1, indp_.size(1) - 1 - counter2)\n",
        "        b2 = (sb_.gather(1, counter2) - s_.gather(1, counter2) * p_.gather(1, indcurr)).squeeze(1)\n",
        "        c = b_ - b2 > 0\n",
        "\n",
        "        lb = torch.where(c, counter4, lb)\n",
        "        ub = torch.where(c, ub, counter4)\n",
        "\n",
        "    lb = lb.long()\n",
        "\n",
        "    if c_l.any():\n",
        "        lmbd_opt = torch.clamp_min((b[c_l] - sb[c_l, -1]) / (-s[c_l, -1]), min=0).unsqueeze(-1)\n",
        "        d[c_l] = (2 * a[c_l] - 1) * lmbd_opt\n",
        "\n",
        "    lmbd_opt = torch.clamp_min((b[c2] - sb[c2, lb]) / (-s[c2, lb]), min=0).unsqueeze(-1)\n",
        "    d[c2] = torch.min(lmbd_opt, d[c2]) * a[c2] + torch.max(-lmbd_opt, d[c2]) * (1 - a[c2])\n",
        "\n",
        "    return d * (w != 0).float()\n",
        "\n",
        "\n",
        "def projection_l2(points_to_project, w_hyperplane, b_hyperplane):\n",
        "    device = points_to_project.device\n",
        "    t, w, b = points_to_project, w_hyperplane.clone(), b_hyperplane\n",
        "\n",
        "    c = (w * t).sum(1) - b\n",
        "    ind2 = 2 * (c >= 0) - 1\n",
        "    w.mul_(ind2.unsqueeze(1))\n",
        "    c.mul_(ind2)\n",
        "\n",
        "    r = torch.max(t / w, (t - 1) / w).clamp(min=-1e12, max=1e12)\n",
        "    r.masked_fill_(w.abs() < 1e-8, 1e12)\n",
        "    r[r == -1e12] *= -1\n",
        "    rs, indr = torch.sort(r, dim=1)\n",
        "    rs2 = F.pad(rs[:, 1:], (0, 1))\n",
        "    rs.masked_fill_(rs == 1e12, 0)\n",
        "    rs2.masked_fill_(rs2 == 1e12, 0)\n",
        "\n",
        "    w3s = (w ** 2).gather(1, indr)\n",
        "    w5 = w3s.sum(dim=1, keepdim=True)\n",
        "    ws = w5 - torch.cumsum(w3s, dim=1)\n",
        "    d = -(r * w)\n",
        "    d.mul_((w.abs() > 1e-8).float())\n",
        "    s = torch.cat((-w5 * rs[:, 0:1], torch.cumsum((-rs2 + rs) * ws, dim=1) - w5 * rs[:, 0:1]), 1)\n",
        "\n",
        "    c4 = s[:, 0] + c < 0\n",
        "    c3 = (d * w).sum(dim=1) + c > 0\n",
        "    c2 = ~(c4 | c3)\n",
        "\n",
        "    lb = torch.zeros(c2.sum(), device=device)\n",
        "    ub = torch.full_like(lb, w.shape[1] - 1)\n",
        "    nitermax = math.ceil(math.log2(w.shape[1]))\n",
        "\n",
        "    s_, c_ = s[c2], c[c2]\n",
        "    for counter in range(nitermax):\n",
        "        counter4 = torch.floor((lb + ub) / 2)\n",
        "        counter2 = counter4.long().unsqueeze(1)\n",
        "        c3 = s_.gather(1, counter2).squeeze(1) + c_ > 0\n",
        "        lb = torch.where(c3, counter4, lb)\n",
        "        ub = torch.where(c3, ub, counter4)\n",
        "\n",
        "    lb = lb.long()\n",
        "\n",
        "    if c4.any():\n",
        "        alpha = c[c4] / w5[c4].squeeze(-1)\n",
        "        d[c4] = -alpha.unsqueeze(-1) * w[c4]\n",
        "\n",
        "    if c2.any():\n",
        "        alpha = (s[c2, lb] + c[c2]) / ws[c2, lb] + rs[c2, lb]\n",
        "        alpha[ws[c2, lb] == 0] = 0\n",
        "        c5 = (alpha.unsqueeze(-1) > r[c2]).float()\n",
        "        d[c2] = d[c2] * c5 - alpha.unsqueeze(-1) * w[c2] * (1 - c5)\n",
        "\n",
        "    return d * (w.abs() > 1e-8).float()\n",
        "\n",
        "\n",
        "def projection_l1(points_to_project, w_hyperplane, b_hyperplane):\n",
        "    device = points_to_project.device\n",
        "    t, w, b = points_to_project, w_hyperplane.clone(), b_hyperplane\n",
        "\n",
        "    c = (w * t).sum(1) - b\n",
        "    ind2 = 2 * (c >= 0) - 1\n",
        "    w.mul_(ind2.unsqueeze(1))\n",
        "    c.mul_(ind2)\n",
        "\n",
        "    r = (1 / w).abs().clamp_max(1e12)\n",
        "    indr = torch.argsort(r, dim=1)\n",
        "    indr_rev = torch.argsort(indr)\n",
        "\n",
        "    c6 = (w < 0).float()\n",
        "    d = (-t + c6) * (w != 0).float()\n",
        "    ds = torch.min(-w * t, w * (1 - t)).gather(1, indr)\n",
        "    ds2 = torch.cat((c.unsqueeze(-1), ds), 1)\n",
        "    s = torch.cumsum(ds2, dim=1)\n",
        "\n",
        "    c2 = s[:, -1] < 0\n",
        "\n",
        "    lb = torch.zeros(c2.sum(), device=device)\n",
        "    ub = torch.full_like(lb, s.shape[1])\n",
        "    nitermax = math.ceil(math.log2(w.shape[1]))\n",
        "\n",
        "    s_ = s[c2]\n",
        "    for counter in range(nitermax):\n",
        "        counter4 = torch.floor((lb + ub) / 2)\n",
        "        counter2 = counter4.long().unsqueeze(1)\n",
        "        c3 = s_.gather(1, counter2).squeeze(1) > 0\n",
        "        lb = torch.where(c3, counter4, lb)\n",
        "        ub = torch.where(c3, ub, counter4)\n",
        "\n",
        "    lb2 = lb.long()\n",
        "\n",
        "    if c2.any():\n",
        "        indr = indr[c2].gather(1, lb2.unsqueeze(1)).squeeze(1)\n",
        "        u = torch.arange(0, w.shape[0], device=device).unsqueeze(1)\n",
        "        u2 = torch.arange(0, w.shape[1], device=device, dtype=torch.float).unsqueeze(0)\n",
        "        alpha = -s[c2, lb2] / w[c2, indr]\n",
        "        c5 = u2 < lb.unsqueeze(-1)\n",
        "        u3 = c5[u[:c5.shape[0]], indr_rev[c2]]\n",
        "        d[c2] = d[c2] * u3.float()\n",
        "        d[c2, indr] = alpha\n",
        "\n",
        "    return d * (w.abs() > 1e-8).float()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQrcS6LwJWQz"
      },
      "source": [
        "##FGSM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_j6ND_5HUHP"
      },
      "source": [
        "class FGSM(Attack):\n",
        "    r\"\"\"\n",
        "    FGSM in the paper 'Explaining and harnessing adversarial examples'\n",
        "    [https://arxiv.org/abs/1412.6572]\n",
        "    \n",
        "    Distance Measure : Linf\n",
        "\n",
        "    Arguments:\n",
        "        model (nn.Module): model to attack.\n",
        "        eps (float): maximum perturbation. (DEFALUT: 0.007)\n",
        "    \n",
        "    Shape:\n",
        "        - images: :math:`(N, C, H, W)` where `N = number of batches`, `C = number of channels`,        `H = height` and `W = width`. It must have a range [0, 1].\n",
        "        - labels: :math:`(N)` where each value :math:`y_i` is :math:`0 \\leq y_i \\leq` `number of labels`.\n",
        "        - output: :math:`(N, C, H, W)`.\n",
        "          \n",
        "    Examples::\n",
        "        >>> attack = torchattacks.FGSM(model, eps=0.007)\n",
        "        >>> adv_images = attack(images, labels)\n",
        "        \n",
        "    \"\"\"\n",
        "    def __init__(self, model, eps=0.007):\n",
        "        super(FGSM, self).__init__(\"FGSM\", model)\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, images, labels):\n",
        "        r\"\"\"\n",
        "        Overridden.\n",
        "        \"\"\"\n",
        "        images = images.clone().detach().to(self.device)\n",
        "        labels = labels.clone().detach().to(self.device)\n",
        "        labels = self._transform_label(images, labels)\n",
        "        \n",
        "        loss = nn.CrossEntropyLoss()\n",
        "\n",
        "        images.requires_grad = True\n",
        "        outputs = self.model(images)\n",
        "        cost = self._targeted*loss(outputs, labels)\n",
        "\n",
        "        grad = torch.autograd.grad(cost, images,\n",
        "                                   retain_graph=False, create_graph=False)[0]\n",
        "\n",
        "        adv_images = images - self.eps*grad.sign()\n",
        "        adv_images = torch.clamp(adv_images, min=0, max=1).detach()\n",
        "\n",
        "        return adv_images\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pApJTgjrJZc_"
      },
      "source": [
        "##MIFGSM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-W3hrmwHemL"
      },
      "source": [
        "class MIFGSM(Attack):\n",
        "    r\"\"\"\n",
        "    MI-FGSM in the paper 'Boosting Adversarial Attacks with Momentum'\n",
        "    [https://arxiv.org/abs/1710.06081]\n",
        "\n",
        "    Distance Measure : Linf\n",
        "\n",
        "    Arguments:\n",
        "        model (nn.Module): model to attack.\n",
        "        eps (float): maximum perturbation. (DEFALUT: 8/255)\n",
        "        decay (float): momentum factor. (DEFAULT: 1.0)\n",
        "        steps (int): number of iterations. (DEFAULT: 5)\n",
        "\n",
        "    Shape:\n",
        "        - images: :math:`(N, C, H, W)` where `N = number of batches`, `C = number of channels`,        `H = height` and `W = width`. It must have a range [0, 1].\n",
        "        - labels: :math:`(N)` where each value :math:`y_i` is :math:`0 \\leq y_i \\leq` `number of labels`.\n",
        "        - output: :math:`(N, C, H, W)`.\n",
        "\n",
        "    Examples::\n",
        "        >>> attack = torchattacks.MIFGSM(model, eps=8/255, steps=5, decay=1.0)\n",
        "        >>> adv_images = attack(images, labels)\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model, eps=8/255, steps=5, decay=1.0):\n",
        "        super(MIFGSM, self).__init__(\"MIFGSM\", model)\n",
        "        self.eps = eps\n",
        "        self.steps = steps\n",
        "        self.decay = decay\n",
        "        self.alpha = self.eps / self.steps\n",
        "\n",
        "    def forward(self, images, labels):\n",
        "        r\"\"\"\n",
        "        Overridden.\n",
        "        \"\"\"\n",
        "        images = images.clone().detach().to(self.device)\n",
        "        labels = labels.clone().detach().to(self.device)\n",
        "        labels = self._transform_label(images, labels)\n",
        "        \n",
        "        loss = nn.CrossEntropyLoss()\n",
        "        momentum = torch.zeros_like(images).detach().to(self.device)\n",
        "\n",
        "        adv_images = images.clone().detach()\n",
        "        \n",
        "        for i in range(self.steps):\n",
        "            adv_images.requires_grad = True\n",
        "            outputs = self.model(adv_images)\n",
        "\n",
        "            cost = self._targeted*loss(outputs, labels)\n",
        "            \n",
        "            grad = torch.autograd.grad(cost, adv_images, \n",
        "                                       retain_graph=False, create_graph=False)[0]\n",
        "            \n",
        "            grad_norm = torch.norm(nn.Flatten()(grad), p=1, dim=1)\n",
        "            grad = grad / grad_norm.view([-1]+[1]*(len(grad.shape)-1))\n",
        "            grad = grad + momentum*self.decay\n",
        "            momentum = grad\n",
        "\n",
        "            adv_images = adv_images.detach() - self.alpha*grad.sign()\n",
        "            delta = torch.clamp(adv_images - images, min=-self.eps, max=self.eps)\n",
        "            adv_images = torch.clamp(images + delta, min=0, max=1).detach()\n",
        "\n",
        "        return adv_images\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ackh82jyJsBq"
      },
      "source": [
        "# Load Params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWjONRP91P2Z"
      },
      "source": [
        "## Define Params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgK5-COccS2i"
      },
      "source": [
        "def _attr_check(args: dict):\n",
        "    if 'dataset' in args:\n",
        "        if not isinstance(args['dataset'], str):\n",
        "            raise TypeError(\"Dataset must of type str\")\n",
        "        if args['dataset'] not in dataset_names:\n",
        "            raise ValueError(\"Dataset must be fashionmnist or emnist\")\n",
        "\n",
        "    if 'workers' in args:\n",
        "        if not isinstance(args['workers'], int):\n",
        "            raise TypeError(\"Work number of data loading workers must be an integer(default: 4)\")\n",
        "\n",
        "    if 'epochs' in args:\n",
        "        if not isinstance(args['epochs'], int):\n",
        "            raise TypeError(\"Number of total epochs to runmust be an integer\")\n",
        "\n",
        "    if 'train_batch' in args:\n",
        "        if not isinstance(args['train_batch'], int):\n",
        "            raise TypeError(\"Training batch must be an integer\")\n",
        "\n",
        "    if 'test_batch' in args:\n",
        "        if not isinstance(args['test_batch'], int):\n",
        "            raise TypeError(\"Testing batch must be an integer\")\n",
        "\n",
        "    if 'learning_rate' in args:\n",
        "        if not isinstance(args['learning_rate'], float):\n",
        "            raise TypeError(\"Learning rate must be a float\")\n",
        "\n",
        "    if 'dropout' in args:\n",
        "        if not isinstance(args['dropout'], float):\n",
        "            raise TypeError(\"Dropout must be a float\")\n",
        "\n",
        "    if 'schedule' in args:\n",
        "        if not isinstance(args['schedule'], list):\n",
        "            raise TypeError(\"Decrease learning rate schedule must be of type list\")\n",
        "\n",
        "    if 'gamma' in args:\n",
        "        if not isinstance(args['gamma'], float):\n",
        "            raise TypeError(\"Gamma must be a float\")\n",
        "\n",
        "    if 'momentum' in args:\n",
        "        if not isinstance(args['momentum'], float):\n",
        "            raise TypeError(\"Momentum must be a float\")\n",
        "\n",
        "    if 'weight_decay' in args:\n",
        "        if not isinstance(args['weight_decay'], float):\n",
        "            raise TypeError(\"Weight Decay must be a float\")\n",
        "\n",
        "    if 'k' in args:\n",
        "        if not isinstance(args['k'], int):\n",
        "            raise TypeError(\"Top k accuracy must be a integer\")\n",
        "\n",
        "    if 'c' in args:\n",
        "        if not isinstance(args['c'], str):\n",
        "            raise TypeError(\"Checkpoint path must be a string\")\n",
        "\n",
        "    if 'resume' in args:\n",
        "        if not isinstance(args['resume'], str):\n",
        "            raise TypeError(\"Resume path must be a string\")\n",
        "\n",
        "    if 'arch' in args:\n",
        "        if not isinstance(args['arch'], str):\n",
        "            raise TypeError(\"Arch must be a string\")\n",
        "        if args['arch'] not in arch_names:\n",
        "            raise ValueError(\"Arch must be defined\")\n",
        "\n",
        "    if 'depth' in args:\n",
        "        if not isinstance(args['depth'], int):\n",
        "            raise TypeError(\"Depth must be an integer\")\n",
        "\n",
        "    if 'widen_factor' in args:\n",
        "        if not isinstance(args.widen_factor, int):\n",
        "            raise TypeError(\"Widen Factor must be an integer\")\n",
        "\n",
        "    if 'growthRate' in args:\n",
        "        if not isinstance(args['growthRate'], int):\n",
        "            raise TypeError(\"Growth Rate must be an integer\")\n",
        "\n",
        "    if 'compressionRate' in args:\n",
        "        if not isinstance(args['compressionRate'], int):\n",
        "            raise TypeError(\"Compression Rate must be an integer\")\n",
        "\n",
        "    if 'manualSeed' in args:\n",
        "        if not isinstance(args['manualSeed'], int):\n",
        "            raise TypeError(\"Manual Seed must be an integer\")\n",
        "\n",
        "    if 'p' in args:\n",
        "        if not isinstance(args['p'], float):\n",
        "            raise TypeError(\"probability must be a float\")\n",
        "\n",
        "    if 'sh' in args:\n",
        "        if not isinstance(args['sh'], float):\n",
        "            raise TypeError(\"maximum erasing area must be a float\")\n",
        "\n",
        "    if 'r1' in args:\n",
        "        if not isinstance(args['r1'], float):\n",
        "            raise TypeError(\"aspect of erasing area must be a float\")\n",
        "\n",
        "    if 'attack_method' in args:\n",
        "        if not isinstance(args['attack_method'], str):\n",
        "            raise TypeError(\"Attack method must be a string\")\n",
        "        if args['attack_method']not in attack_names:\n",
        "            raise ValueError(\"Attack Method must be defined\")\n",
        "\n",
        "    if 'attack_param' in args:\n",
        "        if not isinstance(args['attack_param'], dict):\n",
        "            raise TypeError(\"Attack Param must be a dict eg. {'eps':0.1,} (no space in between)\")\n",
        "\n",
        "\n",
        "class AttrDict(dict):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(AttrDict, self).__init__(*args, **kwargs)\n",
        "        self.__dict__ = self\n",
        "        self.dataset = 'fashionmnist'\n",
        "        self.workers = 4  # number of data loading workers\n",
        "        # Optimization options\n",
        "        self.epochs = 300  # number of total epochs to run\n",
        "        self.train_batch = 128\n",
        "        self.test_batch = 100\n",
        "        self.learning_rate = 0.1\n",
        "        self.dropout = 0\n",
        "        self.schedule = [150, 225]\n",
        "        self.gamma = 0.1\n",
        "        self.momentum = 0.9\n",
        "        self.weight_decay = 5e-4\n",
        "        self.k = 5  # top k accuracy\n",
        "        # Checkpoints\n",
        "        self.checkpoint = 'checkpoint'  # path to save checkpoint (default: checkpoint)\n",
        "        self.resume = ''\n",
        "        # path to specified checkpoint (default: none)\n",
        "        # 'e.g. checkpoint/fashionmnist/timestamp. '\n",
        "        # useful for\n",
        "        # 1. preemption: it will load the checkpoint.pth.tar and resume training,\n",
        "        # 2. when evaluation==True, it will load model_best.pth.tar and do the evaluation\n",
        "        # Architecture\n",
        "        self.arch = 'resnet'\n",
        "        self.depth = 20\n",
        "        self.widen_factor = 10  # Widen factor. 10\n",
        "        self.growthRate = 12  # Growth rate for DenseNet\n",
        "        self.compressionRate = 2  # Compression Rate (theta) for DenseNet\n",
        "        # Random Erasing\n",
        "        self.p = 0  # Random Erasing probability\n",
        "        self.sh = 0.4  # max erasing area\n",
        "        self.r1 = 0.3  # aspect of erasing area\n",
        "        # attack method\n",
        "        self.attack_method = 'PGD'\n",
        "        self.attack_param = \"{}\"\n",
        "        # the parameters for the attack method.\n",
        "        # eg.{'eps':0.1,} (no space in between)\n",
        "        # Miscs\n",
        "        self.manualSeed = None\n",
        "        self.evaluate = None  # 'evaluate model on validation set\n",
        "\n",
        "    def update_attr(self, args: dict):\n",
        "        _attr_check(args)\n",
        "        self.update(args)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7KtLv5c30kU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bbbcfb4-c81f-47dc-cae3-f315f8beac9c"
      },
      "source": [
        "args = AttrDict()\n",
        "print(args)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'dataset': 'fashionmnist', 'workers': 4, 'epochs': 300, 'train_batch': 128, 'test_batch': 100, 'learning_rate': 0.1, 'dropout': 0, 'schedule': [150, 225], 'gamma': 0.1, 'momentum': 0.9, 'weight_decay': 0.0005, 'k': 5, 'checkpoint': 'checkpoint', 'resume': '', 'arch': 'resnet', 'depth': 20, 'widen_factor': 10, 'growthRate': 12, 'compressionRate': 2, 'p': 0, 'sh': 0.4, 'r1': 0.3, 'attack_method': 'PGD', 'attack_param': '{}', 'manualSeed': None, 'evaluate': None}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pMd7IgCEyfB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3I2syD28kKb"
      },
      "source": [
        "## Set Parms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJD6Ny2l9Igv",
        "outputId": "2425a43b-eecc-4820-e141-c06a7bf429cf"
      },
      "source": [
        "# Usage examples\n",
        "### Template for changing the arguments\n",
        "# For example, if we would like to run models on emnist\n",
        "args_emnist = AttrDict()\n",
        "print(args_emnist)\n",
        "new_dict = {'dataset':'emnist'}\n",
        "args_emnist.update_attr(new_dict)\n",
        "print(args_emnist)\n",
        "# if we would like to run wrn instead\n",
        "new_dict2 = {'arch':'wrn'}\n",
        "args_emnist.update_attr(new_dict2)\n",
        "print(args_emnist)\n",
        "# if we would like to run FAB attack instead\n",
        "new_dict3 = {'attack_method':'FAB'}\n",
        "args_emnist.update_attr(new_dict3)\n",
        "print(args_emnist)\n",
        "# if we would like to tune some hyperparameters\n",
        "new_dict4 = {'train_batch':32}\n",
        "args_emnist.update_attr(new_dict4)\n",
        "print(args_emnist)\n",
        "# For the whole set of attributes, refer to class AttrDict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'dataset': 'fashionmnist', 'workers': 4, 'epochs': 300, 'train_batch': 128, 'test_batch': 100, 'learning_rate': 0.1, 'dropout': 0, 'schedule': [150, 225], 'gamma': 0.1, 'momentum': 0.9, 'weight_decay': 0.0005, 'k': 5, 'checkpoint': 'checkpoint', 'resume': '', 'arch': 'resnet', 'depth': 20, 'widen_factor': 10, 'growthRate': 12, 'compressionRate': 2, 'p': 0, 'sh': 0.4, 'r1': 0.3, 'attack_method': 'PGD', 'attack_param': '{}', 'manualSeed': None, 'evaluate': None}\n",
            "{'dataset': 'emnist', 'workers': 4, 'epochs': 300, 'train_batch': 128, 'test_batch': 100, 'learning_rate': 0.1, 'dropout': 0, 'schedule': [150, 225], 'gamma': 0.1, 'momentum': 0.9, 'weight_decay': 0.0005, 'k': 5, 'checkpoint': 'checkpoint', 'resume': '', 'arch': 'resnet', 'depth': 20, 'widen_factor': 10, 'growthRate': 12, 'compressionRate': 2, 'p': 0, 'sh': 0.4, 'r1': 0.3, 'attack_method': 'PGD', 'attack_param': '{}', 'manualSeed': None, 'evaluate': None}\n",
            "{'dataset': 'emnist', 'workers': 4, 'epochs': 300, 'train_batch': 128, 'test_batch': 100, 'learning_rate': 0.1, 'dropout': 0, 'schedule': [150, 225], 'gamma': 0.1, 'momentum': 0.9, 'weight_decay': 0.0005, 'k': 5, 'checkpoint': 'checkpoint', 'resume': '', 'arch': 'wrn', 'depth': 20, 'widen_factor': 10, 'growthRate': 12, 'compressionRate': 2, 'p': 0, 'sh': 0.4, 'r1': 0.3, 'attack_method': 'PGD', 'attack_param': '{}', 'manualSeed': None, 'evaluate': None}\n",
            "{'dataset': 'emnist', 'workers': 4, 'epochs': 300, 'train_batch': 128, 'test_batch': 100, 'learning_rate': 0.1, 'dropout': 0, 'schedule': [150, 225], 'gamma': 0.1, 'momentum': 0.9, 'weight_decay': 0.0005, 'k': 5, 'checkpoint': 'checkpoint', 'resume': '', 'arch': 'wrn', 'depth': 20, 'widen_factor': 10, 'growthRate': 12, 'compressionRate': 2, 'p': 0, 'sh': 0.4, 'r1': 0.3, 'attack_method': 'FAB', 'attack_param': '{}', 'manualSeed': None, 'evaluate': None}\n",
            "{'dataset': 'emnist', 'workers': 4, 'epochs': 300, 'train_batch': 32, 'test_batch': 100, 'learning_rate': 0.1, 'dropout': 0, 'schedule': [150, 225], 'gamma': 0.1, 'momentum': 0.9, 'weight_decay': 0.0005, 'k': 5, 'checkpoint': 'checkpoint', 'resume': '', 'arch': 'wrn', 'depth': 20, 'widen_factor': 10, 'growthRate': 12, 'compressionRate': 2, 'p': 0, 'sh': 0.4, 'r1': 0.3, 'attack_method': 'FAB', 'attack_param': '{}', 'manualSeed': None, 'evaluate': None}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBGnykWvaXfp"
      },
      "source": [
        "global checkpoint_path\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "args.attack_param = eval(args.attack_param)\n",
        "# Use CUDA\n",
        "use_cuda = torch.cuda.is_available()\n",
        "# Random seed\n",
        "if args.manualSeed is None:\n",
        "    args.manualSeed = random.randint(1, 10000)\n",
        "random.seed(args.manualSeed)\n",
        "torch.manual_seed(args.manualSeed)\n",
        "if use_cuda:\n",
        "    torch.cuda.manual_seed_all(args.manualSeed)\n",
        "best_acc = 0  # best test accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52dTclKzrtxB"
      },
      "source": [
        "#Train and Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBKoFtdjrtDL"
      },
      "source": [
        "def train(trainloader, model, criterion, optimizer, epoch, use_cuda, k):\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "    top5 = AverageMeter()\n",
        "    end = time.time()\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        if use_cuda:\n",
        "            inputs, targets = inputs.cuda(), targets.cuda(non_blocking=True)\n",
        "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
        "\n",
        "        # compute output\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, k))\n",
        "        losses.update(loss.item(), inputs.size(0))\n",
        "        top1.update(prec1.item(), inputs.size(0))\n",
        "        top5.update(prec5.item(), inputs.size(0))\n",
        "\n",
        "        # compute gradient and do SGD step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "    return (losses.avg, top1.avg, top5.avg)\n",
        "\n",
        "\n",
        "def test(testloader, model, criterion, epoch, use_cuda, k):\n",
        "    global best_acc\n",
        "\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "    top5 = AverageMeter()\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "\n",
        "    end = time.time()\n",
        "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        if use_cuda:\n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "        inputs, targets = torch.autograd.Variable(inputs, requires_grad=False), torch.autograd.Variable(targets)\n",
        "\n",
        "        # compute output\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, k))\n",
        "        losses.update(loss.item(), inputs.size(0))\n",
        "        top1.update(prec1.item(), inputs.size(0))\n",
        "        top5.update(prec5.item(), inputs.size(0))\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "    return (losses.avg, top1.avg, top5.avg)\n",
        "\n",
        "\n",
        "def robustness_test(testloader, model, criterion, epoch, use_cuda, k, attack_method=None, attack_param={}):\n",
        "    if attack_method is None:\n",
        "        print('no attack_method')\n",
        "        return\n",
        "\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "    top5 = AverageMeter()\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "\n",
        "    end = time.time()\n",
        "\n",
        "    atk = attack_method(model, **attack_param)\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "        inputs = atk(inputs, targets)\n",
        "        if use_cuda:\n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "        inputs, targets = torch.autograd.Variable(inputs, requires_grad=False), torch.autograd.Variable(targets)\n",
        "\n",
        "        # compute output\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, k))\n",
        "        losses.update(loss.item(), inputs.size(0))\n",
        "        top1.update(prec1.item(), inputs.size(0))\n",
        "        top5.update(prec5.item(), inputs.size(0))\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "    return (losses.avg, top1.avg, top5.avg)\n",
        "\n",
        "\n",
        "def save_checkpoint(state, is_best, checkpoint='checkpoint', filename='checkpoint.pth.tar'):\n",
        "    filepath = os.path.join(checkpoint, filename)\n",
        "    torch.save(state, filepath)\n",
        "    if is_best:\n",
        "        shutil.copyfile(filepath, os.path.join(checkpoint, 'model_best.pth.tar'))\n",
        "\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch):\n",
        "    global state\n",
        "    if epoch in args.schedule:\n",
        "        state['lr'] *= args.gamma\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = state['lr']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY4JKsBBlCcV"
      },
      "source": [
        "# Main Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j95uGNwKlu17"
      },
      "source": [
        "import torchvision.transforms as transforms\n",
        "from emnist import extract_training_samples, extract_test_samples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2Ddx6lcdDHc"
      },
      "source": [
        "def main(args):\n",
        "    global best_acc\n",
        "    start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
        "    checkpoint_path = f\"{args.checkpoint}/{args.dataset}/{str(int(time.time()))}\"\n",
        "    if not os.path.isdir(checkpoint_path):\n",
        "        mkdir_p(checkpoint_path)\n",
        "\n",
        "    if args.dataset == 'fashionmnist':\n",
        "        # Data\n",
        "        print('==> Preparing dataset %s' % args.dataset)\n",
        "        transform_train = transforms.Compose([\n",
        "            transforms.RandomCrop(28, padding=4),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.1307,), (0.3081,)),\n",
        "            RandomErasing(probability=args.p, sh=args.sh, r1=args.r1,\n",
        "                                     mean=[0.4914]),\n",
        "        ])\n",
        "        transform_test = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.1307,), (0.3081,)),\n",
        "        ])\n",
        "        dataloader = datasets.FashionMNIST\n",
        "        num_classes = 10\n",
        "        trainset = dataloader(root='./data', train=True, download=True, transform=transform_train)\n",
        "        trainloader = data.DataLoader(trainset, batch_size=args.train_batch, shuffle=True, num_workers=args.workers)\n",
        "\n",
        "        testset = dataloader(root='./data', train=False, download=True, transform=transform_test)\n",
        "        testloader = data.DataLoader(testset, batch_size=args.test_batch, shuffle=False, num_workers=args.workers)\n",
        "\n",
        "    elif args.dataset == 'emnist':\n",
        "        print('==> Preparing dataset %s' % args.dataset)\n",
        "        transform_train = transforms.Compose([\n",
        "            transforms.RandomCrop(28, padding=4),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.1307,), (0.3081,)),\n",
        "            RandomErasing(probability=args.p, sh=args.sh, r1=args.r1,\n",
        "                                     mean=[0.4914]),\n",
        "        ])\n",
        "        transform_test = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.1307,), (0.3081,)),\n",
        "        ])\n",
        "        # https://pypi.org/project/emnist/\n",
        "        train_images, train_labels = extract_training_samples('byclass')\n",
        "        test_images, test_labels = extract_test_samples('byclass')\n",
        "        # train_images = train_images / 255.0\n",
        "        # test_images = test_images / 255.0\n",
        "        num_classes = 62\n",
        "        train_dataset = CustomDataset(train_images, torch.LongTensor(train_labels),\n",
        "                                      transform_train)\n",
        "        val_dataset = CustomDataset(test_images, torch.LongTensor(test_labels), transform_test)\n",
        "        trainloader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                                  batch_size=args.train_batch,\n",
        "                                                  shuffle=True)\n",
        "        testloader = torch.utils.data.DataLoader(val_dataset,\n",
        "                                                 batch_size=args.test_batch,\n",
        "                                                 shuffle=False)\n",
        "    else:\n",
        "        raise NotImplementedError('unrecognized dataset name')\n",
        "\n",
        "    # Model   \n",
        "    print(\"==> creating model '{}'\".format(args.arch))\n",
        "    if args.arch.startswith('wrn'):\n",
        "        model = wrn(\n",
        "                    num_classes=num_classes,\n",
        "                    depth=args.depth,\n",
        "                    widen_factor=args.widen_factor,\n",
        "                    dropRate=args.drop,\n",
        "                )\n",
        "    elif args.arch.endswith('resnet'):\n",
        "        model = resnet(\n",
        "                    num_classes=num_classes,\n",
        "                    depth=args.depth,\n",
        "                )\n",
        "\n",
        "    model = torch.nn.DataParallel(model).to(DEVICE)\n",
        "    cudnn.benchmark = True\n",
        "    print('    Total params: %.2fM' % (sum(p.numel() for p in model.parameters())/1000000.0))\n",
        "    attack_method = eval(args.attack_method)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=args.learning_rate, momentum=args.momentum, weight_decay=args.weight_decay)\n",
        "\n",
        "    # Resume\n",
        "    title = f'{args.dataset}-' + args.arch\n",
        "    if args.resume:\n",
        "        # Load checkpoint.\n",
        "        print('==> Resuming from checkpoint..')\n",
        "        assert os.path.isfile(f'{args.resume}/checkpoint.pth.tar'), 'Error: no checkpoint directory found!'\n",
        "        checkpoint_path = os.path.dirname(args.resume)\n",
        "        checkpoint = torch.load(f'{args.resume}/checkpoint.pth.tar', map_location=DEVICE)\n",
        "        best_acc = checkpoint['best_acc']\n",
        "        start_epoch = checkpoint['epoch']\n",
        "        model.load_state_dict(checkpoint['state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "        logger = Logger(os.path.join(checkpoint_path, 'log.txt'), title=title, resume=True)\n",
        "\n",
        "    elif args.evaluate:\n",
        "        # Load checkpoint.\n",
        "        print('==> evaluating from best model..')\n",
        "        assert os.path.isfile(\n",
        "            f'{args.resume}/model_best.pth.tar'), 'Error: no checkpoint directory found!'\n",
        "        checkpoint_path = os.path.dirname(args.resume)\n",
        "        checkpoint = torch.load(f'{args.resume}/model_best.pth.tar',\n",
        "                                map_location=DEVICE)\n",
        "        best_acc = checkpoint['best_acc']\n",
        "        start_epoch = checkpoint['epoch']\n",
        "        model.load_state_dict(checkpoint['state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "        logger = Logger(os.path.join(checkpoint_path, 'log.txt'), title=title,\n",
        "                        resume=True)\n",
        "\n",
        "        print('\\nEvaluation only')\n",
        "        test_loss, test_acc, test_acc_topk = test(testloader, model, criterion, start_epoch,\n",
        "                                                    use_cuda, args.k)\n",
        "        print(' Test Loss:  %.8f, Test Acc:  %.2f, Test Acc Topk:  %.2f' % (test_loss, test_acc, test_acc_topk))\n",
        "\n",
        "        rtest_loss, rtest_acc, rtest_acc_topk = robustness_test(testloader, model, criterion,\n",
        "                                                  start_epoch,\n",
        "                                                  use_cuda, args.k,\n",
        "                                                                attack_method, args.attack_param)\n",
        "        print('Robustness test: Loss:  %.8f, Acc:  %.2f, Acc Topk:  %.2f' % (\n",
        "        rtest_loss, rtest_acc, rtest_acc_topk))\n",
        "        return\n",
        "\n",
        "    else:\n",
        "        print('models stored at ', checkpoint_path)\n",
        "        logger = Logger(os.path.join(checkpoint_path, 'log.txt'), title=title)\n",
        "        logger.set_names(['Learning Rate', 'Train Loss', 'Valid Loss',\n",
        "                          'Train Acc.', 'Valid Acc.',\n",
        "                          'Train topk acc.', 'Valid topk acc.'])\n",
        "\n",
        "    # Train and val\n",
        "    for epoch in range(start_epoch, args.epochs):\n",
        "        adjust_learning_rate(optimizer, epoch)\n",
        "\n",
        "        print('\\nEpoch: [%d | %d] LR: %f' % (epoch + 1, args.epochs, args.learning_rate))\n",
        "\n",
        "        train_loss, train_acc, train_topk_acc = train(trainloader, model, criterion, optimizer, epoch, use_cuda, args.k)\n",
        "        test_loss, test_acc, test_topk_acc = test(testloader, model, criterion, epoch, use_cuda, args.k)\n",
        "\n",
        "        # append logger file\n",
        "        logger.append([args.learning_rate, train_loss, test_loss, train_acc, test_acc,\n",
        "                       train_topk_acc, test_topk_acc])\n",
        "\n",
        "        # save model\n",
        "        is_best = test_acc > best_acc\n",
        "        best_acc = max(test_acc, best_acc)\n",
        "        save_checkpoint({\n",
        "                'epoch': epoch + 1,\n",
        "                'state_dict': model.state_dict(),\n",
        "                'acc': test_acc,\n",
        "                'best_acc': best_acc,\n",
        "                'optimizer' : optimizer.state_dict(),\n",
        "            }, is_best, checkpoint=checkpoint_path)\n",
        "\n",
        "    logger.close()\n",
        "    logger.plot()\n",
        "    savefig(os.path.join(checkpoint_path, 'log.eps'))\n",
        "\n",
        "    print('Best acc:')\n",
        "    print(best_acc)\n",
        "\n",
        "    test_loss, test_acc, test_acc_topk = test(testloader, model, criterion,\n",
        "                                              start_epoch,\n",
        "                                              use_cuda, args.k)\n",
        "    print(' Test Loss:  %.8f, Test Acc:  %.2f, Test Acc Topk:  %.2f' % (\n",
        "    test_loss, test_acc, test_acc_topk))\n",
        "\n",
        "    rtest_loss, rtest_acc, rtest_acc_topk = robustness_test(testloader, model,\n",
        "                                                            criterion,\n",
        "                                                            start_epoch,\n",
        "                                                            use_cuda, args.k,\n",
        "                                                            attack_method,\n",
        "                                                            args.attack_param)\n",
        "    print('Robustness test: Loss:  %.8f, Acc:  %.2f, Acc Topk:  %.2f' % (\n",
        "        rtest_loss, rtest_acc, rtest_acc_topk))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "TGoyEPK9kF3t",
        "outputId": "bb4f2579-b276-437b-bf84-07af2725287b"
      },
      "source": [
        "main(args)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Preparing dataset fashionmnist\n",
            "==> creating model 'resnet'\n",
            "    Total params: 0.27M\n",
            "models stored at  checkpoint/fashionmnist/1614186902\n",
            "\n",
            "Epoch: [1 | 300] LR: 0.100000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-162-b3f47c9a9b7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-161-52ade98bb7d7>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nEpoch: [%d | %d] LR: %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_topk_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_topk_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-159-a999bbafedff>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(trainloader, model, criterion, optimizer, epoch, use_cuda, k)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# compute gradient and do SGD step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}